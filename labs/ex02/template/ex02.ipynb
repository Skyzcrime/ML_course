{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "height, weight, gender = load_data(sub_sample=False, add_outlier=False)\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((10000,), (10000, 2))"
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NB: throughout this laboratory the data has the following format: \n",
    "  * there are **N = 10000** data entries\n",
    "  * **y** represents the column vector containing weight information -- that which we wish to predict/the output (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,)**.\n",
    "  * **tx** represents the matrix $\\tilde{X}$ formed by laterally concatenating a column vector of 1s to the column vector of height information -- the input data (see also the first page of $\\texttt{exercise02.pdf}$). Its **shape** is **(N,2)**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Computing the Cost Function\n",
    "Fill in the `compute_loss` function below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_loss(y, tx, w):\n",
    "    \"\"\"Calculate the loss using either MSE or MAE.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        the value of the loss (a scalar), corresponding to the input parameters w.\n",
    "    \"\"\"\n",
    "    errors = y- np.dot(tx,w)\n",
    "    mse = np.mean(errors ** 2)\n",
    "    return mse\n",
    "   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Grid Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fill in the function `grid_search()` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from costs import *\n",
    "\n",
    "\n",
    "def grid_search(y, tx, grid_w0, grid_w1):\n",
    "    \"\"\"Algorithm for grid search.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        grid_w0: numpy array of shape=(num_grid_pts_w0, ). A 1D array containing num_grid_pts_w0 values of parameter w0 to be tested in the grid search.\n",
    "        grid_w1: numpy array of shape=(num_grid_pts_w1, ). A 1D array containing num_grid_pts_w1 values of parameter w1 to be tested in the grid search.\n",
    "\n",
    "    Returns:\n",
    "        losses: numpy array of shape=(num_grid_pts_w0, num_grid_pts_w1). A 2D array containing the loss value for each combination of w0 and w1\n",
    "    \"\"\"\n",
    "\n",
    "    losses = np.zeros((len(grid_w0), len(grid_w1)))\n",
    "\n",
    "    for i, w0 in enumerate(grid_w0):\n",
    "        for j, w1 in enumerate(grid_w1):\n",
    "\n",
    "            w = np.array([w0, w1])\n",
    "        \n",
    "            losses[i, j] = compute_loss(y, tx, w)\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us play with the grid search demo now!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Grid Search: loss*=84.84896629356496, w0*=66.66666666666669, w1*=16.666666666666686, execution time=0.005 seconds\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 3 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from grid_search import generate_w, get_best_parameters\n",
    "from plots import grid_visualization\n",
    "\n",
    "# Generate the grid of parameters to be swept\n",
    "grid_w0, grid_w1 = generate_w(num_intervals=10)\n",
    "\n",
    "# Start the grid search\n",
    "start_time = datetime.datetime.now()\n",
    "grid_losses = grid_search(y, tx, grid_w0, grid_w1)\n",
    "\n",
    "# Select the best combinaison\n",
    "loss_star, w0_star, w1_star = get_best_parameters(grid_w0, grid_w1, grid_losses)\n",
    "end_time = datetime.datetime.now()\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "\n",
    "# Print the results\n",
    "print(\n",
    "    \"Grid Search: loss*={l}, w0*={w0}, w1*={w1}, execution time={t:.3f} seconds\".format(\n",
    "        l=loss_star, w0=w0_star, w1=w1_star, t=execution_time\n",
    "    )\n",
    ")\n",
    "\n",
    "# Plot the results\n",
    "fig = grid_visualization(grid_losses, grid_w0, grid_w1, mean_x, std_x, height, weight)\n",
    "fig.set_size_inches(10.0, 6.0)\n",
    "fig.savefig(\"grid_plot\")  # Optional saving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Gradient Descent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again, please fill in the functions `compute_gradient` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def compute_gradient(y, tx, w):\n",
    "    \"\"\"Computes the gradient of the MSE loss at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N,)\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2,). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2,), containing the gradient of the loss at w.\n",
    "    \"\"\"\n",
    "    errors = y - np.dot(tx, w)\n",
    "    \n",
    "    gradient = -(1 / len(y)) * np.dot(tx.T, errors)\n",
    "    \n",
    "    return gradient\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please fill in the functions `gradient_descent` below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The Gradient Descent (GD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of GD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of GD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        gradient = compute_gradient(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        w = w - gamma*gradient\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"GD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your gradient descent function through gradient descent demo shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=5584.473425518335, w0=51.30574540147361, w1=9.435798704492278\n",
      "GD iter. 1/49: loss=530.6049242179212, w0=66.69746902191571, w1=12.266538315840002\n",
      "GD iter. 2/49: loss=75.75675910088253, w0=71.31498610804834, w1=13.11576019924433\n",
      "GD iter. 3/49: loss=34.82042424034894, w0=72.70024123388814, w1=13.37052676426563\n",
      "GD iter. 4/49: loss=31.136154102900914, w0=73.11581777164007, w1=13.446956733772023\n",
      "GD iter. 5/49: loss=30.80456979053059, w0=73.24049073296565, w1=13.469885724623941\n",
      "GD iter. 6/49: loss=30.77472720241726, w0=73.27789262136334, w1=13.476764421879516\n",
      "GD iter. 7/49: loss=30.77204136948706, w0=73.28911318788263, w1=13.478828031056189\n",
      "GD iter. 8/49: loss=30.771799644523348, w0=73.29247935783842, w1=13.47944711380919\n",
      "GD iter. 9/49: loss=30.77177788927661, w0=73.29348920882516, w1=13.47963283863509\n",
      "GD iter. 10/49: loss=30.7717759313044, w0=73.29379216412119, w1=13.479688556082861\n",
      "GD iter. 11/49: loss=30.771775755086907, w0=73.29388305071, w1=13.479705271317192\n",
      "GD iter. 12/49: loss=30.771775739227333, w0=73.29391031668663, w1=13.479710285887492\n",
      "GD iter. 13/49: loss=30.771775737799967, w0=73.29391849647962, w1=13.479711790258582\n",
      "GD iter. 14/49: loss=30.7717757376715, w0=73.29392095041752, w1=13.479712241569908\n",
      "GD iter. 15/49: loss=30.771775737659947, w0=73.29392168659889, w1=13.479712376963306\n",
      "GD iter. 16/49: loss=30.7717757376589, w0=73.2939219074533, w1=13.479712417581325\n",
      "GD iter. 17/49: loss=30.771775737658807, w0=73.29392197370962, w1=13.479712429766732\n",
      "GD iter. 18/49: loss=30.7717757376588, w0=73.29392199358652, w1=13.479712433422353\n",
      "GD iter. 19/49: loss=30.771775737658807, w0=73.2939219995496, w1=13.47971243451904\n",
      "GD iter. 20/49: loss=30.771775737658796, w0=73.29392200133852, w1=13.479712434848047\n",
      "GD iter. 21/49: loss=30.7717757376588, w0=73.29392200187519, w1=13.479712434946748\n",
      "GD iter. 22/49: loss=30.7717757376588, w0=73.29392200203618, w1=13.479712434976358\n",
      "GD iter. 23/49: loss=30.7717757376588, w0=73.29392200208449, w1=13.479712434985242\n",
      "GD iter. 24/49: loss=30.7717757376588, w0=73.29392200209898, w1=13.479712434987906\n",
      "GD iter. 25/49: loss=30.771775737658796, w0=73.29392200210333, w1=13.479712434988706\n",
      "GD iter. 26/49: loss=30.7717757376588, w0=73.29392200210464, w1=13.479712434988945\n",
      "GD iter. 27/49: loss=30.7717757376588, w0=73.29392200210502, w1=13.479712434989018\n",
      "GD iter. 28/49: loss=30.7717757376588, w0=73.29392200210513, w1=13.47971243498904\n",
      "GD iter. 29/49: loss=30.7717757376588, w0=73.29392200210518, w1=13.479712434989047\n",
      "GD iter. 30/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 31/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 32/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 33/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 34/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 35/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 36/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 37/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 38/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 39/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 40/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 41/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 42/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 43/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 44/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 45/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 46/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 47/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 48/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD iter. 49/49: loss=30.7717757376588, w0=73.29392200210519, w1=13.479712434989048\n",
      "GD: execution time=0.010 seconds\n"
     ]
    }
   ],
   "source": [
    "# from gradient_descent import *\n",
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "gd_losses, gd_ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ee726e02e9954b65be82126e512c1b1e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 4. Stochastic gradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_stoch_gradient(y, tx, w):\n",
    "    \"\"\"Compute a stochastic gradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the stochastic gradient of the loss at w.\n",
    "    \"\"\"\n",
    "\n",
    "    return compute_gradient(y,tx,w)\n",
    "\n",
    "\n",
    "def stochastic_gradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"The Stochastic Gradient Descent algorithm (SGD).\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic gradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "\n",
    "        for y_batch, tx_batch in batch_iter(y, tx, batch_size):\n",
    "            gradient = compute_stoch_gradient(y_batch, tx_batch, w)\n",
    "            loss = compute_loss(y_batch, tx_batch, w)\n",
    "            w = w - gamma * gradient\n",
    "            \n",
    "            # Store w and loss\n",
    "            ws.append(w)\n",
    "            losses.append(loss)\n",
    "\n",
    "            print(\n",
    "                \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                    bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/49: loss=4151.144821495182, w0=6.4429378558970924, w1=-4.518951896392679\n",
      "SGD iter. 1/49: loss=2525.9130866825267, w0=11.468784139541796, w1=-7.949944221221688\n",
      "SGD iter. 2/49: loss=612.5628118062459, w0=13.943784769453323, w1=-11.252437754211076\n",
      "SGD iter. 3/49: loss=8861.325728448948, w0=23.357246262681493, w1=3.439075968282271\n",
      "SGD iter. 4/49: loss=3141.089915312758, w0=28.961788987393973, w1=5.366337727677714\n",
      "SGD iter. 5/49: loss=1132.2462600760393, w0=32.32667570179617, w1=3.592923990113937\n",
      "SGD iter. 6/49: loss=366.7990924549365, w0=34.24187567165555, w1=-0.1984657518441586\n",
      "SGD iter. 7/49: loss=466.6425226522723, w0=36.402066687867475, w1=-2.7888685077560047\n",
      "SGD iter. 8/49: loss=3429.079061648372, w0=42.257900583777065, w1=5.552699109823331\n",
      "SGD iter. 9/49: loss=1201.0298168684785, w0=45.7234882927645, w1=4.391006257059935\n",
      "SGD iter. 10/49: loss=370.3689240330771, w0=47.64798543236507, w1=4.2967414411648015\n",
      "SGD iter. 11/49: loss=1753.4035069526406, w0=51.83535155792973, w1=10.417885758151936\n",
      "SGD iter. 12/49: loss=515.4717031436558, w0=54.10575174984228, w1=11.662488602518987\n",
      "SGD iter. 13/49: loss=114.69862137338518, w0=55.17672617238179, w1=11.567802797577215\n",
      "SGD iter. 14/49: loss=327.8926391824303, w0=56.987506775277765, w1=12.369911672877851\n",
      "SGD iter. 15/49: loss=538.5643871237254, w0=59.3082057801548, w1=17.560040194993988\n",
      "SGD iter. 16/49: loss=396.56871649731653, w0=61.29960909565198, w1=16.451740397559043\n",
      "SGD iter. 17/49: loss=205.38703669036485, w0=62.73274215538637, w1=16.976819722862476\n",
      "SGD iter. 18/49: loss=397.6906086495745, w0=64.72696031960405, w1=14.969388661308948\n",
      "SGD iter. 19/49: loss=0.32122031056213207, w0=64.78363662069737, w1=15.087679608527836\n",
      "SGD iter. 20/49: loss=162.7492000632883, w0=66.05936856771166, w1=15.653465387496404\n",
      "SGD iter. 21/49: loss=1.0974373841437783, w0=66.16412721337605, w1=15.722878032252499\n",
      "SGD iter. 22/49: loss=11.783247161849442, w0=66.50739456052473, w1=15.32388876054342\n",
      "SGD iter. 23/49: loss=3.0477660702265017, w0=66.33281603749779, w1=15.059358883718765\n",
      "SGD iter. 24/49: loss=101.99736630913029, w0=67.34275349253711, w1=15.221054446683114\n",
      "SGD iter. 25/49: loss=8.616702046392327, w0=67.6362956879093, w1=15.273065292052115\n",
      "SGD iter. 26/49: loss=21.969144695835723, w0=68.1050082298349, w1=15.120331743537069\n",
      "SGD iter. 27/49: loss=15.207078913797933, w0=67.71504568145623, w1=15.098379362142976\n",
      "SGD iter. 28/49: loss=11.377345098473645, w0=67.37774247811429, w1=14.37219478951362\n",
      "SGD iter. 29/49: loss=1.0136249085683322, w0=67.27706353748773, w1=14.527800566029814\n",
      "SGD iter. 30/49: loss=5.192445201416072, w0=67.04919416259466, w1=14.553826904703023\n",
      "SGD iter. 31/49: loss=9.041701229801687, w0=67.349888379862, w1=14.985221316749966\n",
      "SGD iter. 32/49: loss=4.485357192340394, w0=67.1381017610132, w1=15.21294478980256\n",
      "SGD iter. 33/49: loss=55.01613456136949, w0=67.87983038093675, w1=15.250851267878874\n",
      "SGD iter. 34/49: loss=29.934416816149522, w0=67.3327068408094, w1=15.451720757482938\n",
      "SGD iter. 35/49: loss=99.9692008745501, w0=68.33255283332299, w1=15.312449617730271\n",
      "SGD iter. 36/49: loss=11.45550633154135, w0=68.67101267335636, w1=15.690358764563587\n",
      "SGD iter. 37/49: loss=185.79295208685352, w0=70.03407155721594, w1=15.187621397801776\n",
      "SGD iter. 38/49: loss=84.37419798675826, w0=70.95262584514212, w1=15.010315825792455\n",
      "SGD iter. 39/49: loss=1.4496023639331206, w0=71.07302527885895, w1=15.19493701992424\n",
      "SGD iter. 40/49: loss=2.2162789481881284, w0=71.22189700042446, w1=15.376668711754307\n",
      "SGD iter. 41/49: loss=221.3943148944039, w0=69.73396449222926, w1=15.368981975165823\n",
      "SGD iter. 42/49: loss=246.76993464884458, w0=71.30485575087464, w1=15.4049302319258\n",
      "SGD iter. 43/49: loss=92.22750528327578, w0=70.3445042252171, w1=13.325620515358539\n",
      "SGD iter. 44/49: loss=1.0541254255119317, w0=70.24183361474302, w1=13.340336248928796\n",
      "SGD iter. 45/49: loss=6.028801582740122, w0=70.48736979502486, w1=13.593391661922647\n",
      "SGD iter. 46/49: loss=14.738908966230534, w0=70.87128266230376, w1=13.012056392920737\n",
      "SGD iter. 47/49: loss=9.7237094893661, w0=71.18311129295473, w1=13.400892952382112\n",
      "SGD iter. 48/49: loss=89.78511609417524, w0=72.13066137656074, w1=11.776670238016841\n",
      "SGD iter. 49/49: loss=1.75868983954515, w0=71.99804577266944, w1=11.99678171622025\n",
      "SGD: execution time=0.004 seconds\n"
     ]
    }
   ],
   "source": [
    "# from stochastic_gradient_descent import *\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.1\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SGD.\n",
    "start_time = datetime.datetime.now()\n",
    "sgd_losses, sgd_ws = stochastic_gradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e2731672e6a742848df8c5e1cf003d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 230,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        sgd_losses,\n",
    "        sgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(sgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Effect of Outliers and MAE Cost Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [],
   "source": [
    "import datetime\n",
    "from helpers import *\n",
    "\n",
    "# ***************************************************\n",
    "# INSERT YOUR CODE HERE\n",
    "# TODO: reload the data by subsampling first, then by subsampling and adding outliers\n",
    "# ***************************************************\n",
    "#height, weight, gender = load_data(sub_sample=True, add_outlier=False)\n",
    "height, weight, gender = load_data(sub_sample=True, add_outlier=True)\n",
    "\n",
    "x, mean_x, std_x = standardize(height)\n",
    "y, tx = build_model_data(x, weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((202,), (202, 2))"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.shape, tx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GD iter. 0/49: loss=5739.670229071705, w0=51.847464098448484, w1=7.724426406192441\n",
      "GD iter. 1/49: loss=636.56424940319, w0=67.401703327983, w1=10.041754328050121\n",
      "GD iter. 2/49: loss=177.2847112330252, w0=72.06797509684336, w1=10.736952704607413\n",
      "GD iter. 3/49: loss=135.94955279771042, w0=73.46785662750146, w1=10.945512217574594\n",
      "GD iter. 4/49: loss=132.22938853853208, w0=73.88782108669889, w1=11.00808007146475\n",
      "GD iter. 5/49: loss=131.89457375520604, w0=74.01381042445813, w1=11.026850427631796\n",
      "GD iter. 6/49: loss=131.8644404247067, w0=74.05160722578589, w1=11.03248153448191\n",
      "GD iter. 7/49: loss=131.86172842496174, w0=74.06294626618423, w1=11.034170866536943\n",
      "GD iter. 8/49: loss=131.86148434498472, w0=74.06634797830372, w1=11.034677666153454\n",
      "GD iter. 9/49: loss=131.86146237778675, w0=74.06736849193958, w1=11.034829706038407\n",
      "GD iter. 10/49: loss=131.86146040073896, w0=74.06767464603033, w1=11.034875318003893\n",
      "GD iter. 11/49: loss=131.86146022280465, w0=74.06776649225756, w1=11.034889001593537\n",
      "GD iter. 12/49: loss=131.86146020679058, w0=74.06779404612573, w1=11.034893106670431\n",
      "GD iter. 13/49: loss=131.86146020534932, w0=74.06780231228618, w1=11.034894338193501\n",
      "GD iter. 14/49: loss=131.86146020521957, w0=74.06780479213431, w1=11.034894707650421\n",
      "GD iter. 15/49: loss=131.8614602052079, w0=74.06780553608876, w1=11.034894818487498\n",
      "GD iter. 16/49: loss=131.86146020520684, w0=74.06780575927509, w1=11.03489485173862\n",
      "GD iter. 17/49: loss=131.86146020520675, w0=74.06780582623098, w1=11.034894861713957\n",
      "GD iter. 18/49: loss=131.86146020520675, w0=74.06780584631775, w1=11.034894864706558\n",
      "GD iter. 19/49: loss=131.86146020520678, w0=74.06780585234378, w1=11.034894865604338\n",
      "GD iter. 20/49: loss=131.86146020520675, w0=74.06780585415159, w1=11.034894865873671\n",
      "GD iter. 21/49: loss=131.86146020520675, w0=74.06780585469393, w1=11.03489486595447\n",
      "GD iter. 22/49: loss=131.86146020520673, w0=74.06780585485663, w1=11.034894865978712\n",
      "GD iter. 23/49: loss=131.86146020520673, w0=74.06780585490544, w1=11.034894865985985\n",
      "GD iter. 24/49: loss=131.86146020520675, w0=74.0678058549201, w1=11.034894865988164\n",
      "GD iter. 25/49: loss=131.86146020520675, w0=74.06780585492449, w1=11.034894865988818\n",
      "GD iter. 26/49: loss=131.86146020520675, w0=74.06780585492581, w1=11.034894865989017\n",
      "GD iter. 27/49: loss=131.86146020520673, w0=74.06780585492619, w1=11.034894865989077\n",
      "GD iter. 28/49: loss=131.86146020520675, w0=74.06780585492632, w1=11.034894865989093\n",
      "GD iter. 29/49: loss=131.86146020520675, w0=74.06780585492635, w1=11.034894865989099\n",
      "GD iter. 30/49: loss=131.86146020520675, w0=74.06780585492636, w1=11.034894865989102\n",
      "GD iter. 31/49: loss=131.86146020520675, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 32/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 33/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 34/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 35/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 36/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 37/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 38/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 39/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 40/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 41/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 42/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 43/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 44/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 45/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 46/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 47/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 48/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD iter. 49/49: loss=131.86146020520678, w0=74.06780585492636, w1=11.0348948659891\n",
      "GD: execution time=0.002 seconds\n"
     ]
    }
   ],
   "source": [
    "from plots import gradient_descent_visualization\n",
    "\n",
    "# Define the parameters of the algorithm.\n",
    "max_iters = 50\n",
    "gamma = 0.7\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Generate or load your data\n",
    "# For example, let's assume you have the following (subsampled) data:\n",
    "# y = np.array([...])  # les valeurs cibles\n",
    "# tx = np.array([...])  # les donnes d'entre\n",
    "\n",
    "# Start gradient descent.\n",
    "start_time = datetime.datetime.now()\n",
    "\n",
    "# Apply gradient descent on the data\n",
    "losses, ws = gradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "\n",
    "\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "execution_time = (end_time - start_time).total_seconds()\n",
    "print(\"GD: execution time={t:.3f} seconds\".format(t=execution_time))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5a61565623f4d42a824b8d8a15fc055",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=51, min=1), Output()), _dom_classes=('widge"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Time Visualization\n",
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        gd_losses,\n",
    "        gd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(gd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# 6. Subgradient descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_subgradient_mae(y, tx, w):\n",
    "    \"\"\"Compute a subgradient of the MAE at w.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        w: numpy array of shape=(2, ). The vector of model parameters.\n",
    "\n",
    "    Returns:\n",
    "        A numpy array of shape (2, ) (same shape as w), containing the subgradient of the MAE at w.\n",
    "    \"\"\"\n",
    "    # Compute the residuals\n",
    "    residuals = y - np.dot(tx, w)  # shape (N, )\n",
    "    \n",
    "    # Compute the subgradient\n",
    "    subgradient = np.zeros_like(w, dtype=np.float64)  # Assure-toi que c'est en float\n",
    "\n",
    "    \n",
    "    for i in range(len(residuals)):\n",
    "        if residuals[i] > 0:\n",
    "            subgradient += -tx[i]  # corresponding to -q(w) where q(w) = y - tx * w\n",
    "        elif residuals[i] < 0:\n",
    "            subgradient += tx[i]   # corresponding to q(w)\n",
    "    \n",
    "    return subgradient / len(y)  # average over N\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subgradient_descent(y, tx, initial_w, max_iters, gamma):\n",
    "    \"\"\"The SubGradient Descent (SubGD) algorithm.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(N, )\n",
    "        tx: numpy array of shape=(N,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        max_iters: a scalar denoting the total number of iterations of GD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubGD\n",
    "    \"\"\"\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "    for n_iter in range(max_iters):\n",
    "        \n",
    "\n",
    "        subgradient = compute_subgradient_mae(y, tx, w)\n",
    "        loss = compute_loss(y, tx, w)\n",
    "        w = w - gamma*subgradient\n",
    "\n",
    "        # store w and loss\n",
    "        ws.append(w)\n",
    "        losses.append(loss)\n",
    "        print(\n",
    "            \"SubGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "            )\n",
    "        )\n",
    "\n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SubGD iter. 0/499: loss=5739.670229071705, w0=0.7, w1=6.109524327590712e-16\n",
      "SubGD iter. 1/499: loss=5636.465300874809, w0=1.4, w1=1.2219048655181425e-15\n",
      "SubGD iter. 2/499: loss=5534.240372677912, w0=2.0999999999999996, w1=1.832857298277214e-15\n",
      "SubGD iter. 3/499: loss=5432.995444481015, w0=2.8, w1=2.443809731036285e-15\n",
      "SubGD iter. 4/499: loss=5332.730516284118, w0=3.5, w1=3.054762163795356e-15\n",
      "SubGD iter. 5/499: loss=5233.44558808722, w0=4.2, w1=3.665714596554428e-15\n",
      "SubGD iter. 6/499: loss=5135.140659890324, w0=4.9, w1=4.276667029313499e-15\n",
      "SubGD iter. 7/499: loss=5037.815731693427, w0=5.6000000000000005, w1=4.887619462072571e-15\n",
      "SubGD iter. 8/499: loss=4941.47080349653, w0=6.300000000000001, w1=5.498571894831642e-15\n",
      "SubGD iter. 9/499: loss=4846.105875299634, w0=7.000000000000001, w1=6.109524327590714e-15\n",
      "SubGD iter. 10/499: loss=4751.720947102735, w0=7.700000000000001, w1=6.720476760349785e-15\n",
      "SubGD iter. 11/499: loss=4658.316018905839, w0=8.4, w1=7.331429193108857e-15\n",
      "SubGD iter. 12/499: loss=4565.891090708942, w0=9.1, w1=7.942381625867928e-15\n",
      "SubGD iter. 13/499: loss=4474.446162512046, w0=9.799999999999999, w1=8.553334058627e-15\n",
      "SubGD iter. 14/499: loss=4383.981234315149, w0=10.499999999999998, w1=9.164286491386072e-15\n",
      "SubGD iter. 15/499: loss=4294.496306118252, w0=11.199999999999998, w1=9.775238924145143e-15\n",
      "SubGD iter. 16/499: loss=4205.991377921354, w0=11.899999999999997, w1=1.0386191356904215e-14\n",
      "SubGD iter. 17/499: loss=4118.4664497244585, w0=12.599999999999996, w1=1.0997143789663286e-14\n",
      "SubGD iter. 18/499: loss=4031.9215215275613, w0=13.299999999999995, w1=1.1608096222422358e-14\n",
      "SubGD iter. 19/499: loss=3946.3565933306645, w0=13.999999999999995, w1=1.2219048655181429e-14\n",
      "SubGD iter. 20/499: loss=3861.7716651337673, w0=14.699999999999994, w1=1.28300010879405e-14\n",
      "SubGD iter. 21/499: loss=3778.166736936871, w0=15.399999999999993, w1=1.3440953520699572e-14\n",
      "SubGD iter. 22/499: loss=3695.5418087399735, w0=16.099999999999994, w1=1.4051905953458644e-14\n",
      "SubGD iter. 23/499: loss=3613.8968805430773, w0=16.799999999999994, w1=1.4662858386217714e-14\n",
      "SubGD iter. 24/499: loss=3533.23195234618, w0=17.499999999999993, w1=1.5273810818976784e-14\n",
      "SubGD iter. 25/499: loss=3453.547024149283, w0=18.199999999999992, w1=1.5884763251735854e-14\n",
      "SubGD iter. 26/499: loss=3374.842095952386, w0=18.89999999999999, w1=1.6495715684494924e-14\n",
      "SubGD iter. 27/499: loss=3297.1171677554894, w0=19.59999999999999, w1=1.7106668117253994e-14\n",
      "SubGD iter. 28/499: loss=3220.3722395585924, w0=20.29999999999999, w1=1.7717620550013064e-14\n",
      "SubGD iter. 29/499: loss=3144.6073113616953, w0=20.99999999999999, w1=1.8328572982772134e-14\n",
      "SubGD iter. 30/499: loss=3069.822383164799, w0=21.69999999999999, w1=1.8939525415531204e-14\n",
      "SubGD iter. 31/499: loss=2996.0174549679014, w0=22.399999999999988, w1=1.9550477848290273e-14\n",
      "SubGD iter. 32/499: loss=2923.1925267710044, w0=23.099999999999987, w1=2.0161430281049343e-14\n",
      "SubGD iter. 33/499: loss=2851.3475985741075, w0=23.799999999999986, w1=2.0772382713808413e-14\n",
      "SubGD iter. 34/499: loss=2780.4826703772114, w0=24.499999999999986, w1=2.1383335146567483e-14\n",
      "SubGD iter. 35/499: loss=2710.5977421803145, w0=25.199999999999985, w1=2.1994287579326553e-14\n",
      "SubGD iter. 36/499: loss=2641.692813983417, w0=25.899999999999984, w1=2.2605240012085623e-14\n",
      "SubGD iter. 37/499: loss=2573.7678857865203, w0=26.599999999999984, w1=2.3216192444844693e-14\n",
      "SubGD iter. 38/499: loss=2506.8229575896235, w0=27.299999999999983, w1=2.3827144877603763e-14\n",
      "SubGD iter. 39/499: loss=2440.8580293927266, w0=27.999999999999982, w1=2.4438097310362833e-14\n",
      "SubGD iter. 40/499: loss=2375.87310119583, w0=28.69999999999998, w1=2.5049049743121903e-14\n",
      "SubGD iter. 41/499: loss=2311.8681729989326, w0=29.39999999999998, w1=2.5660002175880973e-14\n",
      "SubGD iter. 42/499: loss=2248.8432448020358, w0=30.09999999999998, w1=2.6270954608640043e-14\n",
      "SubGD iter. 43/499: loss=2186.798316605139, w0=30.79999999999998, w1=2.6881907041399113e-14\n",
      "SubGD iter. 44/499: loss=2125.7333884082423, w0=31.49999999999998, w1=2.7492859474158183e-14\n",
      "SubGD iter. 45/499: loss=2065.648460211345, w0=32.19999999999998, w1=2.8103811906917253e-14\n",
      "SubGD iter. 46/499: loss=2006.543532014448, w0=32.899999999999984, w1=2.871476433967632e-14\n",
      "SubGD iter. 47/499: loss=1948.4186038175505, w0=33.59999999999999, w1=2.9325716772435396e-14\n",
      "SubGD iter. 48/499: loss=1891.2736756206532, w0=34.29999999999999, w1=2.993666920519447e-14\n",
      "SubGD iter. 49/499: loss=1835.108747423756, w0=34.99999999999999, w1=3.054762163795354e-14\n",
      "SubGD iter. 50/499: loss=1779.9238192268595, w0=35.699999999999996, w1=3.1158574070712615e-14\n",
      "SubGD iter. 51/499: loss=1725.718891029962, w0=36.4, w1=3.176952650347169e-14\n",
      "SubGD iter. 52/499: loss=1672.4939628330649, w0=37.1, w1=3.238047893623076e-14\n",
      "SubGD iter. 53/499: loss=1620.2490346361676, w0=37.800000000000004, w1=3.2991431368989835e-14\n",
      "SubGD iter. 54/499: loss=1568.9841064392704, w0=38.50000000000001, w1=3.360238380174891e-14\n",
      "SubGD iter. 55/499: loss=1518.6991782423734, w0=39.20000000000001, w1=3.421333623450798e-14\n",
      "SubGD iter. 56/499: loss=1469.3942500454764, w0=39.90000000000001, w1=3.4824288667267054e-14\n",
      "SubGD iter. 57/499: loss=1421.069321848579, w0=40.600000000000016, w1=3.543524110002613e-14\n",
      "SubGD iter. 58/499: loss=1373.724393651682, w0=41.30000000000002, w1=3.60461935327852e-14\n",
      "SubGD iter. 59/499: loss=1327.3594654547849, w0=42.00000000000002, w1=3.6657145965544273e-14\n",
      "SubGD iter. 60/499: loss=1281.9745372578877, w0=42.700000000000024, w1=3.7268098398303347e-14\n",
      "SubGD iter. 61/499: loss=1237.5696090609906, w0=43.40000000000003, w1=3.787905083106242e-14\n",
      "SubGD iter. 62/499: loss=1194.1446808640935, w0=44.10000000000003, w1=3.849000326382149e-14\n",
      "SubGD iter. 63/499: loss=1151.6997526671964, w0=44.80000000000003, w1=3.9100955696580566e-14\n",
      "SubGD iter. 64/499: loss=1110.2348244702994, w0=45.500000000000036, w1=3.971190812933964e-14\n",
      "SubGD iter. 65/499: loss=1069.7498962734023, w0=46.20000000000004, w1=4.032286056209871e-14\n",
      "SubGD iter. 66/499: loss=1030.2449680765053, w0=46.90000000000004, w1=4.0933812994857785e-14\n",
      "SubGD iter. 67/499: loss=991.7200398796083, w0=47.59306930693074, w1=0.011147845678271063\n",
      "SubGD iter. 68/499: loss=954.2961338587949, w0=48.279207920792125, w1=0.03308574108989941\n",
      "SubGD iter. 69/499: loss=917.9530476343557, w0=48.96534653465351, w1=0.05502363650152776\n",
      "SubGD iter. 70/499: loss=882.5524963472897, w0=49.63069306930698, w1=0.10538326388307814\n",
      "SubGD iter. 71/499: loss=848.48816536286, w0=50.28910891089114, w1=0.16746568532793435\n",
      "SubGD iter. 72/499: loss=815.3889055581634, w0=50.947524752475296, w1=0.22954810677279056\n",
      "SubGD iter. 73/499: loss=783.1643770484698, w0=51.59207920792084, w1=0.31242512932747524\n",
      "SubGD iter. 74/499: loss=751.991105769746, w0=52.22277227722777, w1=0.4119501328839991\n",
      "SubGD iter. 75/499: loss=721.9139070185919, w0=52.84653465346539, w1=0.5208167847923756\n",
      "SubGD iter. 76/499: loss=692.7496495086656, w0=53.4564356435644, w1=0.6457900912635992\n",
      "SubGD iter. 77/499: loss=664.623540215251, w0=54.0594059405941, w1=0.7796904498577214\n",
      "SubGD iter. 78/499: loss=637.3667449536993, w0=54.655445544554496, w1=0.9197570104995693\n",
      "SubGD iter. 79/499: loss=611.0172068604656, w0=55.24455445544559, w1=1.0670920297849913\n",
      "SubGD iter. 80/499: loss=585.533346834701, w0=55.819801980198065, w1=1.2261255948210765\n",
      "SubGD iter. 81/499: loss=561.0630602323163, w0=56.36732673267331, w1=1.410709342622213\n",
      "SubGD iter. 82/499: loss=537.7933683507081, w0=56.900990099009945, w1=1.605853732220269\n",
      "SubGD iter. 83/499: loss=515.467840105092, w0=57.42772277227727, w1=1.808762802293962\n",
      "SubGD iter. 84/499: loss=493.8753380594152, w0=57.933663366336674, w1=2.0285064197514697\n",
      "SubGD iter. 85/499: loss=473.28704689184497, w0=58.43267326732677, w1=2.2494370848672776\n",
      "SubGD iter. 86/499: loss=453.50309966090003, w0=58.91089108910895, w1=2.4837982986028337\n",
      "SubGD iter. 87/499: loss=434.7147779282262, w0=59.382178217821824, w1=2.7260245553531504\n",
      "SubGD iter. 88/499: loss=416.56644513986333, w0=59.83960396039608, w1=2.978742333469136\n",
      "SubGD iter. 89/499: loss=399.20478298395005, w0=60.262376237623805, w1=3.251528669355438\n",
      "SubGD iter. 90/499: loss=383.03213647440134, w0=60.67821782178222, w1=3.5270865794242794\n",
      "SubGD iter. 91/499: loss=367.5097131703353, w0=61.087128712871326, w1=3.806459183951815\n",
      "SubGD iter. 92/499: loss=352.6097216808271, w0=61.49603960396043, w1=4.085831788479351\n",
      "SubGD iter. 93/499: loss=338.2002445293422, w0=61.891089108910926, w1=4.373839384328607\n",
      "SubGD iter. 94/499: loss=324.50355104765913, w0=62.27920792079211, w1=4.666037469532047\n",
      "SubGD iter. 95/499: loss=311.39484599428704, w0=62.65346534653469, w1=4.959829093241769\n",
      "SubGD iter. 96/499: loss=299.0550535899243, w0=63.02079207920796, w1=5.25705719205664\n",
      "SubGD iter. 97/499: loss=287.28138175243237, w0=63.38118811881192, w1=5.560434316352406\n",
      "SubGD iter. 98/499: loss=276.03497715257123, w0=63.74158415841588, w1=5.863811440648173\n",
      "SubGD iter. 99/499: loss=265.23241852252636, w0=64.08811881188123, w1=6.172402175278548\n",
      "SubGD iter. 100/499: loss=255.0994488495434, w0=64.42772277227726, w1=6.486369310516498\n",
      "SubGD iter. 101/499: loss=245.48174677437166, w0=64.7673267326733, w1=6.800336445754448\n",
      "SubGD iter. 102/499: loss=236.29185712305227, w0=65.10693069306933, w1=7.114303580992399\n",
      "SubGD iter. 103/499: loss=227.52977989558528, w0=65.44653465346536, w1=7.428270716230349\n",
      "SubGD iter. 104/499: loss=219.19551509197066, w0=65.76534653465349, w1=7.747893210218626\n",
      "SubGD iter. 105/499: loss=211.59667085503062, w0=66.070297029703, w1=8.073669686866905\n",
      "SubGD iter. 106/499: loss=204.59046217619974, w0=66.37524752475251, w1=8.399446163515185\n",
      "SubGD iter. 107/499: loss=197.98250373170544, w0=66.6663366336634, w1=8.73297028041739\n",
      "SubGD iter. 108/499: loss=191.94206363616917, w0=66.9574257425743, w1=9.066494397319596\n",
      "SubGD iter. 109/499: loss=186.29356595239688, w0=67.23465346534658, w1=9.39863031947029\n",
      "SubGD iter. 110/499: loss=181.2307934506211, w0=67.51188118811886, w1=9.730766241620982\n",
      "SubGD iter. 111/499: loss=176.54235991095808, w0=67.78910891089114, w1=10.062902163771675\n",
      "SubGD iter. 112/499: loss=172.22826533340793, w0=68.06633663366343, w1=10.363999289979422\n",
      "SubGD iter. 113/499: loss=168.32919389288253, w0=68.32970297029709, w1=10.660466909273612\n",
      "SubGD iter. 114/499: loss=164.9274812145677, w0=68.59306930693076, w1=10.943174379960814\n",
      "SubGD iter. 115/499: loss=161.84261312272287, w0=68.85643564356442, w1=11.225881850648015\n",
      "SubGD iter. 116/499: loss=159.05631571338645, w0=69.11287128712878, w1=11.504395843582206\n",
      "SubGD iter. 117/499: loss=156.63326794432305, w0=69.35544554455453, w1=11.78820189306775\n",
      "SubGD iter. 118/499: loss=154.6352713770206, w0=69.58415841584166, w1=12.060911465190971\n",
      "SubGD iter. 119/499: loss=153.0172646250554, w0=69.80594059405948, w1=12.324245668386048\n",
      "SubGD iter. 120/499: loss=151.68738119863238, w0=70.0277227722773, w1=12.587579871581125\n",
      "SubGD iter. 121/499: loss=150.5945622465042, w0=70.25643564356443, w1=12.824765405096484\n",
      "SubGD iter. 122/499: loss=149.5916396400284, w0=70.47821782178225, w1=13.065616959310148\n",
      "SubGD iter. 123/499: loss=148.87043467320038, w0=70.69306930693077, w1=13.302953389983912\n",
      "SubGD iter. 124/499: loss=148.3943964418495, w0=70.89405940594067, w1=13.525403099312918\n",
      "SubGD iter. 125/499: loss=148.1367579879098, w0=71.08811881188126, w1=13.742945617944212\n",
      "SubGD iter. 126/499: loss=148.07353395486228, w0=71.27524752475254, w1=13.953548196006844\n",
      "SubGD iter. 127/499: loss=148.17837949345358, w0=71.46237623762383, w1=14.164150774069476\n",
      "SubGD iter. 128/499: loss=148.4419662341799, w0=71.62178217821788, w1=14.349779559473173\n",
      "SubGD iter. 129/499: loss=148.83295256332022, w0=71.75346534653471, w1=14.51689010761231\n",
      "SubGD iter. 130/499: loss=149.34192305667597, w0=71.87128712871292, w1=14.670791185324186\n",
      "SubGD iter. 131/499: loss=149.90589676476748, w0=71.95445544554461, w1=14.780276456654521\n",
      "SubGD iter. 132/499: loss=150.3555934177362, w0=72.0376237623763, w1=14.889761727984856\n",
      "SubGD iter. 133/499: loss=150.84309805783067, w0=72.10693069306937, w1=14.985916181776727\n",
      "SubGD iter. 134/499: loss=151.31706104340262, w0=72.17623762376245, w1=15.082070635568597\n",
      "SubGD iter. 135/499: loss=151.8191222882267, w0=72.24554455445552, w1=15.178225089360467\n",
      "SubGD iter. 136/499: loss=152.34928179230306, w0=72.30099009900998, w1=15.25972348971591\n",
      "SubGD iter. 137/499: loss=152.8322750204225, w0=72.34950495049513, w1=15.335091856448138\n",
      "SubGD iter. 138/499: loss=153.3057123601289, w0=72.39801980198028, w1=15.410460223180365\n",
      "SubGD iter. 139/499: loss=153.7952178628723, w0=72.43267326732682, w1=15.469961786755725\n",
      "SubGD iter. 140/499: loss=154.20493737591508, w0=72.46039603960405, w1=15.51864528583281\n",
      "SubGD iter. 141/499: loss=154.5492443470499, w0=72.48811881188128, w1=15.561592159086487\n",
      "SubGD iter. 142/499: loss=154.84785974250644, w0=72.5019801980199, w1=15.597828332032526\n",
      "SubGD iter. 143/499: loss=155.13363200857242, w0=72.52277227722782, w1=15.624722856626713\n",
      "SubGD iter. 144/499: loss=155.3151099450632, w0=72.55049504950505, w1=15.642690329098\n",
      "SubGD iter. 145/499: loss=155.395471315302, w0=72.56435643564366, w1=15.664356578291091\n",
      "SubGD iter. 146/499: loss=155.55373610721833, w0=72.58514851485158, w1=15.677095775361284\n",
      "SubGD iter. 147/499: loss=155.60976227626026, w0=72.6059405940595, w1=15.689834972431477\n",
      "SubGD iter. 148/499: loss=155.66697764070182, w0=72.62673267326743, w1=15.70257416950167\n",
      "SubGD iter. 149/499: loss=155.72538220054292, w0=72.64059405940604, w1=15.72424041869476\n",
      "SubGD iter. 150/499: loss=155.8883554271594, w0=72.66138613861396, w1=15.736979615764954\n",
      "SubGD iter. 151/499: loss=155.94907761771364, w0=72.66831683168327, w1=15.74811029423128\n",
      "SubGD iter. 152/499: loss=156.03442940440473, w0=72.67524752475258, w1=15.759240972697606\n",
      "SubGD iter. 153/499: loss=156.12012504411496, w0=72.68217821782189, w1=15.770371651163932\n",
      "SubGD iter. 154/499: loss=156.20616453684426, w0=72.68217821782189, w1=15.774323911906686\n",
      "SubGD iter. 155/499: loss=156.24361183520176, w0=72.68217821782189, w1=15.77827617264944\n",
      "SubGD iter. 156/499: loss=156.28109037428922, w0=72.68217821782189, w1=15.782228433392193\n",
      "SubGD iter. 157/499: loss=156.31860015410666, w0=72.68217821782189, w1=15.786180694134947\n",
      "SubGD iter. 158/499: loss=156.35614117465403, w0=72.68217821782189, w1=15.7901329548777\n",
      "SubGD iter. 159/499: loss=156.39371343593137, w0=72.68217821782189, w1=15.794085215620454\n",
      "SubGD iter. 160/499: loss=156.43131693793867, w0=72.68217821782189, w1=15.798037476363207\n",
      "SubGD iter. 161/499: loss=156.46895168067596, w0=72.68217821782189, w1=15.801989737105961\n",
      "SubGD iter. 162/499: loss=156.50661766414314, w0=72.68217821782189, w1=15.805941997848715\n",
      "SubGD iter. 163/499: loss=156.54431488834032, w0=72.68217821782189, w1=15.809894258591468\n",
      "SubGD iter. 164/499: loss=156.58204335326744, w0=72.68217821782189, w1=15.813846519334222\n",
      "SubGD iter. 165/499: loss=156.61980305892456, w0=72.68217821782189, w1=15.817798780076975\n",
      "SubGD iter. 166/499: loss=156.65759400531158, w0=72.68217821782189, w1=15.821751040819729\n",
      "SubGD iter. 167/499: loss=156.6954161924286, w0=72.68217821782189, w1=15.825703301562482\n",
      "SubGD iter. 168/499: loss=156.73326962027556, w0=72.68217821782189, w1=15.829655562305236\n",
      "SubGD iter. 169/499: loss=156.77115428885247, w0=72.68217821782189, w1=15.83360782304799\n",
      "SubGD iter. 170/499: loss=156.80907019815933, w0=72.68217821782189, w1=15.837560083790743\n",
      "SubGD iter. 171/499: loss=156.84701734819615, w0=72.68217821782189, w1=15.841512344533497\n",
      "SubGD iter. 172/499: loss=156.88499573896297, w0=72.68217821782189, w1=15.84546460527625\n",
      "SubGD iter. 173/499: loss=156.92300537045975, w0=72.68217821782189, w1=15.849416866019004\n",
      "SubGD iter. 174/499: loss=156.96104624268642, w0=72.68217821782189, w1=15.853369126761757\n",
      "SubGD iter. 175/499: loss=156.9991183556431, w0=72.68217821782189, w1=15.857321387504511\n",
      "SubGD iter. 176/499: loss=157.03722170932969, w0=72.68217821782189, w1=15.861273648247264\n",
      "SubGD iter. 177/499: loss=157.07535630374628, w0=72.68217821782189, w1=15.865225908990018\n",
      "SubGD iter. 178/499: loss=157.11352213889282, w0=72.68217821782189, w1=15.869178169732772\n",
      "SubGD iter. 179/499: loss=157.15171921476932, w0=72.68217821782189, w1=15.873130430475525\n",
      "SubGD iter. 180/499: loss=157.18994753137574, w0=72.68217821782189, w1=15.877082691218279\n",
      "SubGD iter. 181/499: loss=157.22820708871217, w0=72.68217821782189, w1=15.881034951961032\n",
      "SubGD iter. 182/499: loss=157.26649788677852, w0=72.68217821782189, w1=15.884987212703786\n",
      "SubGD iter. 183/499: loss=157.3048199255748, w0=72.68217821782189, w1=15.88893947344654\n",
      "SubGD iter. 184/499: loss=157.34317320510115, w0=72.68217821782189, w1=15.892891734189293\n",
      "SubGD iter. 185/499: loss=157.38155772535737, w0=72.68217821782189, w1=15.896843994932047\n",
      "SubGD iter. 186/499: loss=157.41997348634354, w0=72.68217821782189, w1=15.9007962556748\n",
      "SubGD iter. 187/499: loss=157.45842048805972, w0=72.68217821782189, w1=15.904748516417554\n",
      "SubGD iter. 188/499: loss=157.4968987305058, w0=72.68217821782189, w1=15.908700777160307\n",
      "SubGD iter. 189/499: loss=157.53540821368188, w0=72.68217821782189, w1=15.91265303790306\n",
      "SubGD iter. 190/499: loss=157.57394893758791, w0=72.67524752475258, w1=15.910526938117323\n",
      "SubGD iter. 191/499: loss=157.5724670109085, w0=72.67524752475258, w1=15.914479198860077\n",
      "SubGD iter. 192/499: loss=157.61102216974302, w0=72.67524752475258, w1=15.91843145960283\n",
      "SubGD iter. 193/499: loss=157.64960856930753, w0=72.66831683168327, w1=15.916305359817093\n",
      "SubGD iter. 194/499: loss=157.64819814063867, w0=72.66831683168327, w1=15.920257620559847\n",
      "SubGD iter. 195/499: loss=157.6867989751317, w0=72.66831683168327, w1=15.9242098813026\n",
      "SubGD iter. 196/499: loss=157.72543105035467, w0=72.66831683168327, w1=15.928162142045354\n",
      "SubGD iter. 197/499: loss=157.76409436630763, w0=72.66138613861396, w1=15.926036042259616\n",
      "SubGD iter. 198/499: loss=157.7627386298479, w0=72.66138613861396, w1=15.92998830300237\n",
      "SubGD iter. 199/499: loss=157.80141638072936, w0=72.66138613861396, w1=15.933940563745123\n",
      "SubGD iter. 200/499: loss=157.8401253723408, w0=72.65445544554466, w1=15.931814463959386\n",
      "SubGD iter. 201/499: loss=157.83884113389163, w0=72.65445544554466, w1=15.93576672470214\n",
      "SubGD iter. 202/499: loss=157.87756456043158, w0=72.65445544554466, w1=15.939718985444893\n",
      "SubGD iter. 203/499: loss=157.91631922770148, w0=72.65445544554466, w1=15.943671246187646\n",
      "SubGD iter. 204/499: loss=157.9551051357013, w0=72.64752475247535, w1=15.941545146401909\n",
      "SubGD iter. 205/499: loss=157.95387558946132, w0=72.64752475247535, w1=15.945497407144662\n",
      "SubGD iter. 206/499: loss=157.99267593238966, w0=72.64752475247535, w1=15.949449667887416\n",
      "SubGD iter. 207/499: loss=158.031507516048, w0=72.64059405940604, w1=15.947323568101679\n",
      "SubGD iter. 208/499: loss=158.03034946781855, w0=72.64059405940604, w1=15.951275828844432\n",
      "SubGD iter. 209/499: loss=158.0691954864054, w0=72.64059405940604, w1=15.955228089587186\n",
      "SubGD iter. 210/499: loss=158.1080727457222, w0=72.64059405940604, w1=15.95918035032994\n",
      "SubGD iter. 211/499: loss=158.14698124576896, w0=72.63366336633673, w1=15.957054250544202\n",
      "SubGD iter. 212/499: loss=158.14587788974868, w0=72.63366336633673, w1=15.961006511286955\n",
      "SubGD iter. 213/499: loss=158.18480082472394, w0=72.63366336633673, w1=15.964958772029709\n",
      "SubGD iter. 214/499: loss=158.22375500042918, w0=72.62673267326743, w1=15.962832672243971\n",
      "SubGD iter. 215/499: loss=158.22272314241945, w0=72.63366336633673, w1=15.967301372051375\n",
      "SubGD iter. 216/499: loss=158.24685882383025, w0=72.62673267326743, w1=15.965175272265638\n",
      "SubGD iter. 217/499: loss=158.2458170046177, w0=72.63366336633673, w1=15.969643972073042\n",
      "SubGD iter. 218/499: loss=158.26997362278104, w0=72.62673267326743, w1=15.967517872287305\n",
      "SubGD iter. 219/499: loss=158.26892184236567, w0=72.63366336633673, w1=15.971986572094709\n",
      "SubGD iter. 220/499: loss=158.29309939728157, w0=72.62673267326743, w1=15.969860472308971\n",
      "SubGD iter. 221/499: loss=158.2920376556634, w0=72.63366336633673, w1=15.974329172116375\n",
      "SubGD iter. 222/499: loss=158.31623614733184, w0=72.62673267326743, w1=15.972203072330638\n",
      "SubGD iter. 223/499: loss=158.31516444451083, w0=72.62673267326743, w1=15.970593411609551\n",
      "SubGD iter. 224/499: loss=158.29927225334316, w0=72.63366336633673, w1=15.975062111416955\n",
      "SubGD iter. 225/499: loss=158.32347729558305, w0=72.62673267326743, w1=15.972936011631218\n",
      "SubGD iter. 226/499: loss=158.32240247615786, w0=72.62673267326743, w1=15.97132635091013\n",
      "SubGD iter. 227/499: loss=158.30650792542298, w0=72.63366336633673, w1=15.975795050717535\n",
      "SubGD iter. 228/499: loss=158.33071951823428, w0=72.62673267326743, w1=15.973668950931797\n",
      "SubGD iter. 229/499: loss=158.3296415822049, w0=72.62673267326743, w1=15.97205929021071\n",
      "SubGD iter. 230/499: loss=158.31374467190287, w0=72.62673267326743, w1=15.970449629489623\n",
      "SubGD iter. 231/499: loss=158.29785294361602, w0=72.63366336633673, w1=15.974918329297028\n",
      "SubGD iter. 232/499: loss=158.32205670081765, w0=72.62673267326743, w1=15.97279222951129\n",
      "SubGD iter. 233/499: loss=158.32098249278275, w0=72.62673267326743, w1=15.971182568790203\n",
      "SubGD iter. 234/499: loss=158.30508840492874, w0=72.63366336633673, w1=15.975651268597607\n",
      "SubGD iter. 235/499: loss=158.32929871270176, w0=72.62673267326743, w1=15.97352516881187\n",
      "SubGD iter. 236/499: loss=158.32822138806267, w0=72.62673267326743, w1=15.971915508090783\n",
      "SubGD iter. 237/499: loss=158.31232494064145, w0=72.63366336633673, w1=15.976384207898187\n",
      "SubGD iter. 238/499: loss=158.3365417989859, w0=72.62673267326743, w1=15.97425810811245\n",
      "SubGD iter. 239/499: loss=158.33546135774262, w0=72.62673267326743, w1=15.972648447391363\n",
      "SubGD iter. 240/499: loss=158.3195625507542, w0=72.62673267326743, w1=15.971038786670276\n",
      "SubGD iter. 241/499: loss=158.30366892578107, w0=72.63366336633673, w1=15.97550748647768\n",
      "SubGD iter. 242/499: loss=158.32787794851583, w0=72.62673267326743, w1=15.973381386691942\n",
      "SubGD iter. 243/499: loss=158.326801235267, w0=72.62673267326743, w1=15.971771725970855\n",
      "SubGD iter. 244/499: loss=158.31090525072665, w0=72.63366336633673, w1=15.97624042577826\n",
      "SubGD iter. 245/499: loss=158.33512082403283, w0=72.62673267326743, w1=15.974114325992522\n",
      "SubGD iter. 246/499: loss=158.33404099417987, w0=72.62673267326743, w1=15.972504665271435\n",
      "SubGD iter. 247/499: loss=158.31814265007225, w0=72.62673267326743, w1=15.970895004550348\n",
      "SubGD iter. 248/499: loss=158.30224948798002, w0=72.63366336633673, w1=15.975363704357752\n",
      "SubGD iter. 249/499: loss=158.32645722567648, w0=72.62673267326743, w1=15.973237604572015\n",
      "SubGD iter. 250/499: loss=158.32538112381795, w0=72.62673267326743, w1=15.971627943850928\n",
      "SubGD iter. 251/499: loss=158.30948560215847, w0=72.63366336633673, w1=15.976096643658332\n",
      "SubGD iter. 252/499: loss=158.33369989042637, w0=72.62673267326743, w1=15.973970543872595\n",
      "SubGD iter. 253/499: loss=158.33262067196364, w0=72.62673267326743, w1=15.972360883151508\n",
      "SubGD iter. 254/499: loss=158.31672279073697, w0=72.62673267326743, w1=15.97075122243042\n",
      "SubGD iter. 255/499: loss=158.3008300915255, w0=72.63366336633673, w1=15.975219922237825\n",
      "SubGD iter. 256/499: loss=158.32503654418377, w0=72.62673267326743, w1=15.973093822452087\n",
      "SubGD iter. 257/499: loss=158.32396105371546, w0=72.62673267326743, w1=15.971484161731\n",
      "SubGD iter. 258/499: loss=158.30806599493687, w0=72.63366336633673, w1=15.975952861538405\n",
      "SubGD iter. 259/499: loss=158.33227899816652, w0=72.62673267326743, w1=15.973826761752667\n",
      "SubGD iter. 260/499: loss=158.33120039109406, w0=72.62673267326743, w1=15.97221710103158\n",
      "SubGD iter. 261/499: loss=158.31530297274824, w0=72.62673267326743, w1=15.970607440310493\n",
      "SubGD iter. 262/499: loss=158.29941073641766, w0=72.63366336633673, w1=15.975076140117897\n",
      "SubGD iter. 263/499: loss=158.32361590403758, w0=72.62673267326743, w1=15.97295004033216\n",
      "SubGD iter. 264/499: loss=158.3225410249596, w0=72.62673267326743, w1=15.971340379611073\n",
      "SubGD iter. 265/499: loss=158.30664642906186, w0=72.63366336633673, w1=15.975809079418477\n",
      "SubGD iter. 266/499: loss=158.33085814725322, w0=72.62673267326743, w1=15.97368297963274\n",
      "SubGD iter. 267/499: loss=158.32978015157107, w0=72.62673267326743, w1=15.972073318911653\n",
      "SubGD iter. 268/499: loss=158.31388319610608, w0=72.62673267326743, w1=15.970463658190566\n",
      "SubGD iter. 269/499: loss=158.2979914226564, w0=72.63366336633673, w1=15.97493235799797\n",
      "SubGD iter. 270/499: loss=158.32219530523807, w0=72.62673267326743, w1=15.972806258212232\n",
      "SubGD iter. 271/499: loss=158.32112103755034, w0=72.62673267326743, w1=15.971196597491145\n",
      "SubGD iter. 272/499: loss=158.30522690453347, w0=72.63366336633673, w1=15.97566529729855\n",
      "SubGD iter. 273/499: loss=158.32943733768656, w0=72.62673267326743, w1=15.973539197512812\n",
      "SubGD iter. 274/499: loss=158.32835995339462, w0=72.62673267326743, w1=15.971929536791725\n",
      "SubGD iter. 275/499: loss=158.31246346081053, w0=72.63366336633673, w1=15.97639823659913\n",
      "SubGD iter. 276/499: loss=158.33668044453506, w0=72.62673267326743, w1=15.974272136813392\n",
      "SubGD iter. 277/499: loss=158.33559994363898, w0=72.62673267326743, w1=15.972662476092305\n",
      "SubGD iter. 278/499: loss=158.31970109148767, w0=72.62673267326743, w1=15.971052815371218\n",
      "SubGD iter. 279/499: loss=158.30380742135162, w0=72.63366336633673, w1=15.975521515178622\n",
      "SubGD iter. 280/499: loss=158.32801656946646, w0=72.62673267326743, w1=15.973395415392885\n",
      "SubGD iter. 281/499: loss=158.32693979656483, w0=72.62673267326743, w1=15.971785754671798\n",
      "SubGD iter. 282/499: loss=158.31104376686156, w0=72.63366336633673, w1=15.976254454479202\n",
      "SubGD iter. 283/499: loss=158.33525946554784, w0=72.62673267326743, w1=15.974128354693464\n",
      "SubGD iter. 284/499: loss=158.33417957604206, w0=72.62673267326743, w1=15.972518693972377\n",
      "SubGD iter. 285/499: loss=158.31828118677157, w0=72.62673267326743, w1=15.97090903325129\n",
      "SubGD iter. 286/499: loss=158.3023879795164, w0=72.63366336633673, w1=15.975377733058695\n",
      "SubGD iter. 287/499: loss=158.326595842593, w0=72.62673267326743, w1=15.973251633272957\n",
      "SubGD iter. 288/499: loss=158.3255196810816, w0=72.62673267326743, w1=15.97164197255187\n",
      "SubGD iter. 289/499: loss=158.30962411425924, w0=72.63366336633673, w1=15.976110672359274\n",
      "SubGD iter. 290/499: loss=158.3338385279072, w0=72.62673267326743, w1=15.973984572573537\n",
      "SubGD iter. 291/499: loss=158.33275924979168, w0=72.62673267326743, w1=15.97237491185245\n",
      "SubGD iter. 292/499: loss=158.3168613234021, w0=72.62673267326743, w1=15.970765251131363\n",
      "SubGD iter. 293/499: loss=158.3009685790278, w0=72.63366336633673, w1=15.975233950938767\n",
      "SubGD iter. 294/499: loss=158.3251751570661, w0=72.62673267326743, w1=15.97310785115303\n",
      "SubGD iter. 295/499: loss=158.324099606945, w0=72.62673267326743, w1=15.971498190431943\n",
      "SubGD iter. 296/499: loss=158.30820450300345, w0=72.63366336633673, w1=15.975966890239347\n",
      "SubGD iter. 297/499: loss=158.3324176316132, w0=72.62673267326743, w1=15.97384079045361\n",
      "SubGD iter. 298/499: loss=158.33133896488792, w0=72.62673267326743, w1=15.972231129732522\n",
      "SubGD iter. 299/499: loss=158.31544150137918, w0=72.62673267326743, w1=15.970621469011435\n",
      "SubGD iter. 300/499: loss=158.29954921988573, w0=72.63366336633673, w1=15.97509016881884\n",
      "SubGD iter. 301/499: loss=158.3237545128858, w0=72.62673267326743, w1=15.972964069033102\n",
      "SubGD iter. 302/499: loss=158.322679574155, w0=72.62673267326743, w1=15.971354408312015\n",
      "SubGD iter. 303/499: loss=158.30678493309432, w0=72.63366336633673, w1=15.97582310811942\n",
      "SubGD iter. 304/499: loss=158.33099677666578, w0=72.62673267326743, w1=15.973697008333682\n",
      "SubGD iter. 305/499: loss=158.32991872133078, w0=72.62673267326743, w1=15.972087347612595\n",
      "SubGD iter. 306/499: loss=158.3140217207029, w0=72.62673267326743, w1=15.970477686891508\n",
      "SubGD iter. 307/499: loss=158.29812990209032, w0=72.63366336633673, w1=15.974946386698912\n",
      "SubGD iter. 308/499: loss=158.32233391005215, w0=72.62673267326743, w1=15.972820286913175\n",
      "SubGD iter. 309/499: loss=158.32125958271155, w0=72.62673267326743, w1=15.971210626192088\n",
      "SubGD iter. 310/499: loss=158.30536540453173, w0=72.63366336633673, w1=15.975679325999492\n",
      "SubGD iter. 311/499: loss=158.32957596306494, w0=72.62673267326743, w1=15.973553226213754\n",
      "SubGD iter. 312/499: loss=158.32849851912022, w0=72.62673267326743, w1=15.971943565492667\n",
      "SubGD iter. 313/499: loss=158.3126019813732, w0=72.63366336633673, w1=15.976412265300072\n",
      "SubGD iter. 314/499: loss=158.33681909047786, w0=72.62673267326743, w1=15.974286165514334\n",
      "SubGD iter. 315/499: loss=158.33573852992893, w0=72.62673267326743, w1=15.972676504793247\n",
      "SubGD iter. 316/499: loss=158.31983963261473, w0=72.62673267326743, w1=15.97106684407216\n",
      "SubGD iter. 317/499: loss=158.30394591731576, w0=72.63366336633673, w1=15.975535543879564\n",
      "SubGD iter. 318/499: loss=158.32815519081072, w0=72.62673267326743, w1=15.973409444093827\n",
      "SubGD iter. 319/499: loss=158.32707835825624, w0=72.62673267326743, w1=15.97179978337274\n",
      "SubGD iter. 320/499: loss=158.3111822833901, w0=72.63366336633673, w1=15.976268483180144\n",
      "SubGD iter. 321/499: loss=158.33539810745648, w0=72.62673267326743, w1=15.974142383394407\n",
      "SubGD iter. 322/499: loss=158.3343181582978, w0=72.62673267326743, w1=15.97253272267332\n",
      "SubGD iter. 323/499: loss=158.31841972386448, w0=72.62673267326743, w1=15.970923061952233\n",
      "SubGD iter. 324/499: loss=158.3025264714464, w0=72.63366336633673, w1=15.975391761759637\n",
      "SubGD iter. 325/499: loss=158.3267344599031, w0=72.62673267326743, w1=15.9732656619739\n",
      "SubGD iter. 326/499: loss=158.3256582387389, w0=72.62673267326743, w1=15.971656001252812\n",
      "SubGD iter. 327/499: loss=158.30976262675358, w0=72.63366336633673, w1=15.976124701060217\n",
      "SubGD iter. 328/499: loss=158.3339771657817, w0=72.62673267326743, w1=15.973998601274479\n",
      "SubGD iter. 329/499: loss=158.3328978280133, w0=72.62673267326743, w1=15.972388940553392\n",
      "SubGD iter. 330/499: loss=158.31699985646082, w0=72.62673267326743, w1=15.970779279832305\n",
      "SubGD iter. 331/499: loss=158.3011070669236, w0=72.63366336633673, w1=15.97524797963971\n",
      "SubGD iter. 332/499: loss=158.32531377034206, w0=72.62673267326743, w1=15.973121879853972\n",
      "SubGD iter. 333/499: loss=158.32423816056811, w0=72.62673267326743, w1=15.971512219132885\n",
      "SubGD iter. 334/499: loss=158.3083430114637, w0=72.63366336633673, w1=15.975980918940289\n",
      "SubGD iter. 335/499: loss=158.33255626545358, w0=72.62673267326743, w1=15.973854819154552\n",
      "SubGD iter. 336/499: loss=158.33147753907542, w0=72.62673267326743, w1=15.972245158433465\n",
      "SubGD iter. 337/499: loss=158.31558003040377, w0=72.62673267326743, w1=15.970635497712378\n",
      "SubGD iter. 338/499: loss=158.29968770374742, w0=72.63366336633673, w1=15.975104197519782\n",
      "SubGD iter. 339/499: loss=158.3238931221276, w0=72.62673267326743, w1=15.972978097734044\n",
      "SubGD iter. 340/499: loss=158.32281812374396, w0=72.62673267326743, w1=15.971368437012957\n",
      "SubGD iter. 341/499: loss=158.30692343752037, w0=72.63366336633673, w1=15.975837136820362\n",
      "SubGD iter. 342/499: loss=158.33113540647196, w0=72.62673267326743, w1=15.973711037034624\n",
      "SubGD iter. 343/499: loss=158.33005729148414, w0=72.62673267326743, w1=15.972101376313537\n",
      "SubGD iter. 344/499: loss=158.31416024569333, w0=72.62673267326743, w1=15.97049171559245\n",
      "SubGD iter. 345/499: loss=158.29826838191786, w0=72.63366336633673, w1=15.974960415399854\n",
      "SubGD iter. 346/499: loss=158.3224725152598, w0=72.62673267326743, w1=15.972834315614117\n",
      "SubGD iter. 347/499: loss=158.32139812826637, w0=72.62673267326743, w1=15.97122465489303\n",
      "SubGD iter. 348/499: loss=158.30550390492368, w0=72.63366336633673, w1=15.975693354700434\n",
      "SubGD iter. 349/499: loss=158.329714588837, w0=72.62673267326743, w1=15.973567254914697\n",
      "SubGD iter. 350/499: loss=158.32863708523942, w0=72.62673267326743, w1=15.97195759419361\n",
      "SubGD iter. 351/499: loss=158.31274050232952, w0=72.63366336633673, w1=15.976426294001014\n",
      "SubGD iter. 352/499: loss=158.33695773681424, w0=72.62673267326743, w1=15.974300194215276\n",
      "SubGD iter. 353/499: loss=158.33587711661247, w0=72.62673267326743, w1=15.97269053349419\n",
      "SubGD iter. 354/499: loss=158.3199781741354, w0=72.62673267326743, w1=15.971080872773102\n",
      "SubGD iter. 355/499: loss=158.30408441367354, w0=72.63366336633673, w1=15.975549572580507\n",
      "SubGD iter. 356/499: loss=158.32829381254862, w0=72.62673267326743, w1=15.973423472794769\n",
      "SubGD iter. 357/499: loss=158.3272169203413, w0=72.62673267326743, w1=15.971813812073682\n",
      "SubGD iter. 358/499: loss=158.31132080031227, w0=72.63366336633673, w1=15.976282511881086\n",
      "SubGD iter. 359/499: loss=158.33553674975875, w0=72.62673267326743, w1=15.974156412095349\n",
      "SubGD iter. 360/499: loss=158.33445674094722, w0=72.62673267326743, w1=15.972546751374262\n",
      "SubGD iter. 361/499: loss=158.31855826135097, w0=72.62673267326743, w1=15.970937090653175\n",
      "SubGD iter. 362/499: loss=158.30266496377, w0=72.63366336633673, w1=15.975405790460579\n",
      "SubGD iter. 363/499: loss=158.32687307760685, w0=72.62673267326743, w1=15.973279690674842\n",
      "SubGD iter. 364/499: loss=158.32579679678977, w0=72.62673267326743, w1=15.971670029953755\n",
      "SubGD iter. 365/499: loss=158.30990113964157, w0=72.63366336633673, w1=15.976138729761159\n",
      "SubGD iter. 366/499: loss=158.3341158040498, w0=72.62673267326743, w1=15.974012629975421\n",
      "SubGD iter. 367/499: loss=158.3330364066286, w0=72.62673267326743, w1=15.972402969254334\n",
      "SubGD iter. 368/499: loss=158.31713838991317, w0=72.62673267326743, w1=15.970793308533247\n",
      "SubGD iter. 369/499: loss=158.30124555521306, w0=72.63366336633673, w1=15.975262008340652\n",
      "SubGD iter. 370/499: loss=158.3254523840116, w0=72.62673267326743, w1=15.973135908554914\n",
      "SubGD iter. 371/499: loss=158.32437671458484, w0=72.62673267326743, w1=15.971526247833827\n",
      "SubGD iter. 372/499: loss=158.3084815203175, w0=72.63366336633673, w1=15.975994947641231\n",
      "SubGD iter. 373/499: loss=158.3326948996875, w0=72.62673267326743, w1=15.973868847855494\n",
      "SubGD iter. 374/499: loss=158.33161611365654, w0=72.62673267326743, w1=15.972259187134407\n",
      "SubGD iter. 375/499: loss=158.31571855982202, w0=72.62673267326743, w1=15.97064952641332\n",
      "SubGD iter. 376/499: loss=158.29982618800275, w0=72.63366336633673, w1=15.975118226220724\n",
      "SubGD iter. 377/499: loss=158.32403173176303, w0=72.62673267326743, w1=15.972992126434987\n",
      "SubGD iter. 378/499: loss=158.3229566737265, w0=72.62673267326743, w1=15.9713824657139\n",
      "SubGD iter. 379/499: loss=158.30706194234006, w0=72.63366336633673, w1=15.975851165521304\n",
      "SubGD iter. 380/499: loss=158.33127403667174, w0=72.62673267326743, w1=15.973725065735566\n",
      "SubGD iter. 381/499: loss=158.33019586203108, w0=72.62673267326743, w1=15.97211540501448\n",
      "SubGD iter. 382/499: loss=158.3142987710774, w0=72.62673267326743, w1=15.970505744293392\n",
      "SubGD iter. 383/499: loss=158.29840686213905, w0=72.63366336633673, w1=15.974974444100797\n",
      "SubGD iter. 384/499: loss=158.32261112086104, w0=72.62673267326743, w1=15.972848344315059\n",
      "SubGD iter. 385/499: loss=158.3215366742148, w0=72.62673267326743, w1=15.971238683593972\n",
      "SubGD iter. 386/499: loss=158.3056424057092, w0=72.63366336633673, w1=15.975707383401376\n",
      "SubGD iter. 387/499: loss=158.3298532150026, w0=72.62673267326743, w1=15.973581283615639\n",
      "SubGD iter. 388/499: loss=158.3287756517522, w0=72.62673267326743, w1=15.971971622894552\n",
      "SubGD iter. 389/499: loss=158.31287902367941, w0=72.63366336633673, w1=15.976440322701956\n",
      "SubGD iter. 390/499: loss=158.33709638354424, w0=72.62673267326743, w1=15.974314222916218\n",
      "SubGD iter. 391/499: loss=158.33601570368967, w0=72.62673267326743, w1=15.972704562195132\n",
      "SubGD iter. 392/499: loss=158.32011671604965, w0=72.62673267326743, w1=15.971094901474045\n",
      "SubGD iter. 393/499: loss=158.30422291042493, w0=72.63366336633673, w1=15.975563601281449\n",
      "SubGD iter. 394/499: loss=158.32843243468008, w0=72.62673267326743, w1=15.973437501495711\n",
      "SubGD iter. 395/499: loss=158.32735548281994, w0=72.62673267326743, w1=15.971827840774624\n",
      "SubGD iter. 396/499: loss=158.311459317628, w0=72.63366336633673, w1=15.976296540582029\n",
      "SubGD iter. 397/499: loss=158.3356753924546, w0=72.62673267326743, w1=15.974170440796291\n",
      "SubGD iter. 398/499: loss=158.33459532399027, w0=72.62673267326743, w1=15.972560780075204\n",
      "SubGD iter. 399/499: loss=158.3186967992311, w0=72.62673267326743, w1=15.970951119354117\n",
      "SubGD iter. 400/499: loss=158.30280345648723, w0=72.63366336633673, w1=15.975419819161521\n",
      "SubGD iter. 401/499: loss=158.32701169570413, w0=72.62673267326743, w1=15.973293719375784\n",
      "SubGD iter. 402/499: loss=158.32593535523426, w0=72.62673267326743, w1=15.971684058654697\n",
      "SubGD iter. 403/499: loss=158.3100396529232, w0=72.63366336633673, w1=15.976152758462101\n",
      "SubGD iter. 404/499: loss=158.3342544427115, w0=72.62673267326743, w1=15.974026658676364\n",
      "SubGD iter. 405/499: loss=158.33317498563747, w0=72.62673267326743, w1=15.972416997955277\n",
      "SubGD iter. 406/499: loss=158.31727692375918, w0=72.62673267326743, w1=15.97080733723419\n",
      "SubGD iter. 407/499: loss=158.30138404389615, w0=72.63366336633673, w1=15.975276037041594\n",
      "SubGD iter. 408/499: loss=158.3255909980748, w0=72.62673267326743, w1=15.973149937255856\n",
      "SubGD iter. 409/499: loss=158.32451526899519, w0=72.62673267326743, w1=15.97154027653477\n",
      "SubGD iter. 410/499: loss=158.308620029565, w0=72.63366336633673, w1=15.976008976342174\n",
      "SubGD iter. 411/499: loss=158.33283353431503, w0=72.62673267326743, w1=15.973882876556436\n",
      "SubGD iter. 412/499: loss=158.33175468863126, w0=72.62673267326743, w1=15.972273215835349\n",
      "SubGD iter. 413/499: loss=158.31585708963382, w0=72.62673267326743, w1=15.970663555114262\n",
      "SubGD iter. 414/499: loss=158.29996467265167, w0=72.63366336633673, w1=15.975132254921666\n",
      "SubGD iter. 415/499: loss=158.32417034179204, w0=72.62673267326743, w1=15.973006155135929\n",
      "SubGD iter. 416/499: loss=158.3230952241027, w0=72.62673267326743, w1=15.971396494414842\n",
      "SubGD iter. 417/499: loss=158.30720044755336, w0=72.63366336633673, w1=15.975865194222246\n",
      "SubGD iter. 418/499: loss=158.33141266726517, w0=72.62673267326743, w1=15.973739094436509\n",
      "SubGD iter. 419/499: loss=158.33033443297163, w0=72.62673267326743, w1=15.972129433715422\n",
      "SubGD iter. 420/499: loss=158.31443729685506, w0=72.62673267326743, w1=15.970519772994335\n",
      "SubGD iter. 421/499: loss=158.29854534275378, w0=72.63366336633673, w1=15.974988472801739\n",
      "SubGD iter. 422/499: loss=158.3227497268559, w0=72.62673267326743, w1=15.972862373016001\n",
      "SubGD iter. 423/499: loss=158.3216752205568, w0=72.62673267326743, w1=15.971252712294914\n",
      "SubGD iter. 424/499: loss=158.30578090688832, w0=72.63366336633673, w1=15.975721412102319\n",
      "SubGD iter. 425/499: loss=158.32999184156188, w0=72.62673267326743, w1=15.973595312316581\n",
      "SubGD iter. 426/499: loss=158.32891421865858, w0=72.62673267326743, w1=15.971985651595494\n",
      "SubGD iter. 427/499: loss=158.3130175454229, w0=72.63366336633673, w1=15.976454351402898\n",
      "SubGD iter. 428/499: loss=158.33723503066787, w0=72.62673267326743, w1=15.97432825161716\n",
      "SubGD iter. 429/499: loss=158.33615429116043, w0=72.62673267326743, w1=15.972718590896074\n",
      "SubGD iter. 430/499: loss=158.32025525835752, w0=72.62673267326743, w1=15.971108930174987\n",
      "SubGD iter. 431/499: loss=158.30436140756987, w0=72.63366336633673, w1=15.975577629982391\n",
      "SubGD iter. 432/499: loss=158.32857105720518, w0=72.62673267326743, w1=15.973451530196654\n",
      "SubGD iter. 433/499: loss=158.32749404569216, w0=72.62673267326743, w1=15.971841869475567\n",
      "SubGD iter. 434/499: loss=158.31159783533732, w0=72.63366336633673, w1=15.97631056928297\n",
      "SubGD iter. 435/499: loss=158.33581403554405, w0=72.62673267326743, w1=15.974184469497233\n",
      "SubGD iter. 436/499: loss=158.33473390742685, w0=72.62673267326743, w1=15.972574808776146\n",
      "SubGD iter. 437/499: loss=158.31883533750482, w0=72.62673267326743, w1=15.97096514805506\n",
      "SubGD iter. 438/499: loss=158.30294194959808, w0=72.63366336633673, w1=15.975433847862464\n",
      "SubGD iter. 439/499: loss=158.32715031419505, w0=72.62673267326743, w1=15.973307748076726\n",
      "SubGD iter. 440/499: loss=158.32607391407234, w0=72.62673267326743, w1=15.97169808735564\n",
      "SubGD iter. 441/499: loss=158.31017816659838, w0=72.63366336633673, w1=15.976166787163043\n",
      "SubGD iter. 442/499: loss=158.33439308176682, w0=72.62673267326743, w1=15.974040687377306\n",
      "SubGD iter. 443/499: loss=158.33331356503993, w0=72.62673267326743, w1=15.972431026656219\n",
      "SubGD iter. 444/499: loss=158.31741545799875, w0=72.62673267326743, w1=15.970821365935132\n",
      "SubGD iter. 445/499: loss=158.30152253297283, w0=72.63366336633673, w1=15.975290065742536\n",
      "SubGD iter. 446/499: loss=158.32572961253157, w0=72.62673267326743, w1=15.973163965956799\n",
      "SubGD iter. 447/499: loss=158.32465382379914, w0=72.62673267326743, w1=15.971554305235712\n",
      "SubGD iter. 448/499: loss=158.308758539206, w0=72.63366336633673, w1=15.976023005043116\n",
      "SubGD iter. 449/499: loss=158.3329721693362, w0=72.62673267326743, w1=15.973896905257378\n",
      "SubGD iter. 450/499: loss=158.33189326399955, w0=72.62673267326743, w1=15.972287244536291\n",
      "SubGD iter. 451/499: loss=158.31599561983924, w0=72.62673267326743, w1=15.970677583815204\n",
      "SubGD iter. 452/499: loss=158.3001031576942, w0=72.63366336633673, w1=15.975146283622609\n",
      "SubGD iter. 453/499: loss=158.3243089522147, w0=72.62673267326743, w1=15.973020183836871\n",
      "SubGD iter. 454/499: loss=158.32323377487248, w0=72.62673267326743, w1=15.971410523115784\n",
      "SubGD iter. 455/499: loss=158.30733895316024, w0=72.63366336633673, w1=15.975879222923188\n",
      "SubGD iter. 456/499: loss=158.33155129825218, w0=72.62673267326743, w1=15.97375312313745\n",
      "SubGD iter. 457/499: loss=158.33047300430576, w0=72.62673267326743, w1=15.972143462416364\n",
      "SubGD iter. 458/499: loss=158.31457582302636, w0=72.62673267326743, w1=15.970533801695277\n",
      "SubGD iter. 459/499: loss=158.29868382376213, w0=72.63366336633673, w1=15.975002501502681\n",
      "SubGD iter. 460/499: loss=158.3228883332444, w0=72.62673267326743, w1=15.972876401716944\n",
      "SubGD iter. 461/499: loss=158.32181376729247, w0=72.62673267326743, w1=15.971266740995857\n",
      "SubGD iter. 462/499: loss=158.30591940846105, w0=72.63366336633673, w1=15.97573544080326\n",
      "SubGD iter. 463/499: loss=158.3301304685147, w0=72.62673267326743, w1=15.973609341017523\n",
      "SubGD iter. 464/499: loss=158.32905278595862, w0=72.62673267326743, w1=15.971999680296436\n",
      "SubGD iter. 465/499: loss=158.31315606756004, w0=72.63366336633673, w1=15.97646838010384\n",
      "SubGD iter. 466/499: loss=158.33737367818512, w0=72.62673267326743, w1=15.974342280318103\n",
      "SubGD iter. 467/499: loss=158.33629287902485, w0=72.62673267326743, w1=15.972732619597016\n",
      "SubGD iter. 468/499: loss=158.32039380105903, w0=72.62673267326743, w1=15.97112295887593\n",
      "SubGD iter. 469/499: loss=158.30449990510851, w0=72.63366336633673, w1=15.975591658683333\n",
      "SubGD iter. 470/499: loss=158.32870968012386, w0=72.62673267326743, w1=15.973465558897596\n",
      "SubGD iter. 471/499: loss=158.32763260895803, w0=72.62673267326743, w1=15.971855898176509\n",
      "SubGD iter. 472/499: loss=158.31173635344032, w0=72.63366336633673, w1=15.976324597983913\n",
      "SubGD iter. 473/499: loss=158.33595267902714, w0=72.62673267326743, w1=15.974198498198175\n",
      "SubGD iter. 474/499: loss=158.3348724912571, w0=72.62673267326743, w1=15.972588837477089\n",
      "SubGD iter. 475/499: loss=158.31897387617218, w0=72.62673267326743, w1=15.970979176756002\n",
      "SubGD iter. 476/499: loss=158.3030804431025, w0=72.63366336633673, w1=15.975447876563406\n",
      "SubGD iter. 477/499: loss=158.32728893307961, w0=72.62673267326743, w1=15.973321776777668\n",
      "SubGD iter. 478/499: loss=158.32621247330405, w0=72.62673267326743, w1=15.971712116056581\n",
      "SubGD iter. 479/499: loss=158.31031668066717, w0=72.63366336633673, w1=15.976180815863986\n",
      "SubGD iter. 480/499: loss=158.33453172121574, w0=72.62673267326743, w1=15.974054716078248\n",
      "SubGD iter. 481/499: loss=158.333452144836, w0=72.62673267326743, w1=15.972445055357161\n",
      "SubGD iter. 482/499: loss=158.31755399263193, w0=72.62673267326743, w1=15.970835394636074\n",
      "SubGD iter. 483/499: loss=158.3016610224431, w0=72.63366336633673, w1=15.975304094443478\n",
      "SubGD iter. 484/499: loss=158.32586822738196, w0=72.62673267326743, w1=15.97317799465774\n",
      "SubGD iter. 485/499: loss=158.32479237899668, w0=72.62673267326743, w1=15.971568333936654\n",
      "SubGD iter. 486/499: loss=158.30889704924067, w0=72.63366336633673, w1=15.976037033744058\n",
      "SubGD iter. 487/499: loss=158.33311080475096, w0=72.62673267326743, w1=15.97391093395832\n",
      "SubGD iter. 488/499: loss=158.3320318397615, w0=72.62673267326743, w1=15.972301273237234\n",
      "SubGD iter. 489/499: loss=158.31613415043827, w0=72.62673267326743, w1=15.970691612516147\n",
      "SubGD iter. 490/499: loss=158.3002416431303, w0=72.63366336633673, w1=15.97516031232355\n",
      "SubGD iter. 491/499: loss=158.32444756303093, w0=72.62673267326743, w1=15.973034212537813\n",
      "SubGD iter. 492/499: loss=158.32337232603592, w0=72.62673267326743, w1=15.971424551816726\n",
      "SubGD iter. 493/499: loss=158.3074774591608, w0=72.63366336633673, w1=15.97589325162413\n",
      "SubGD iter. 494/499: loss=158.33168992963274, w0=72.62673267326743, w1=15.973767151838393\n",
      "SubGD iter. 495/499: loss=158.33061157603356, w0=72.62673267326743, w1=15.972157491117306\n",
      "SubGD iter. 496/499: loss=158.3147143495912, w0=72.62673267326743, w1=15.97054783039622\n",
      "SubGD iter. 497/499: loss=158.29882230516415, w0=72.63366336633673, w1=15.975016530203623\n",
      "SubGD iter. 498/499: loss=158.32302694002647, w0=72.62673267326743, w1=15.972890430417886\n",
      "SubGD iter. 499/499: loss=158.32195231442174, w0=72.62673267326743, w1=15.971280769696799\n",
      "SubGD: execution time=0.086 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subgd_losses, subgd_ws = subgradient_descent(y, tx, w_initial, max_iters, gamma)\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80c733c6214d44dc8550741c36893fd0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subgd_losses,\n",
    "        subgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subgd_ws)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stochastic Subgradient Descent\n",
    "\n",
    "**NB** for the computation of the subgradient you can reuse the `compute_subgradient` method that you implemented above, just making sure that you pass in a minibatch as opposed to the full data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stochastic_subgradient_descent(y, tx, initial_w, batch_size, max_iters, gamma):\n",
    "    \"\"\"Compute a stochastic subgradient at w from a data sample batch of size B, where B < N, and their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        y: numpy array of shape=(B, )\n",
    "        tx: numpy array of shape=(B,2)\n",
    "        initial_w: numpy array of shape=(2, ). The initial guess (or the initialization) for the model parameters\n",
    "        batch_size: a scalar denoting the number of data points in a mini-batch used for computing the stochastic subgradient\n",
    "        max_iters: a scalar denoting the total number of iterations of SubSGD\n",
    "        gamma: a scalar denoting the stepsize\n",
    "\n",
    "    Returns:\n",
    "        losses: a list of length max_iters containing the loss value (scalar) for each iteration of SubSGD\n",
    "        ws: a list of length max_iters containing the model parameters as numpy arrays of shape (2, ), for each iteration of SubSGD\n",
    "    \"\"\"\n",
    "\n",
    "    # Define parameters to store w and loss\n",
    "    ws = [initial_w]\n",
    "    losses = []\n",
    "    w = initial_w\n",
    "\n",
    "    for n_iter in range(max_iters):\n",
    "\n",
    "        for y_batch, tx_batch in batch_iter(y, tx, batch_size):\n",
    "            gradient = compute_subgradient_mae(y_batch, tx_batch, w)\n",
    "            loss = compute_loss(y_batch, tx_batch, w)\n",
    "            w = w - gamma * gradient\n",
    "            \n",
    "            # Store w and loss\n",
    "            ws.append(w)\n",
    "            losses.append(loss)\n",
    "\n",
    "            print(\n",
    "                \"SGD iter. {bi}/{ti}: loss={l}, w0={w0}, w1={w1}\".format(\n",
    "                    bi=n_iter, ti=max_iters - 1, l=loss, w0=w[0], w1=w[1]\n",
    "                )\n",
    "            )\n",
    "    \n",
    "    return losses, ws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SGD iter. 0/499: loss=3013.054396861313, w0=0.7, w1=-0.5581237037490393\n",
      "SGD iter. 1/499: loss=7522.579275115192, w0=1.4, w1=-0.09154157778246419\n",
      "SGD iter. 2/499: loss=8378.7392446292, w0=2.0999999999999996, w1=1.0767892227350044\n",
      "SGD iter. 3/499: loss=7361.066386982736, w0=2.8, w1=1.8018094128158086\n",
      "SGD iter. 4/499: loss=7225.652002537986, w0=3.5, w1=2.681539542648287\n",
      "SGD iter. 5/499: loss=3860.056041758409, w0=4.2, w1=2.5610349911692447\n",
      "SGD iter. 6/499: loss=5798.190530846278, w0=4.9, w1=2.7575550739477475\n",
      "SGD iter. 7/499: loss=2977.7156116066767, w0=5.6000000000000005, w1=2.7437998779722568\n",
      "SGD iter. 8/499: loss=2742.972808183024, w0=6.300000000000001, w1=2.2082801951460516\n",
      "SGD iter. 9/499: loss=5796.770485968026, w0=7.000000000000001, w1=2.839445535140904\n",
      "SGD iter. 10/499: loss=4298.958225677278, w0=7.700000000000001, w1=2.712431089912879\n",
      "SGD iter. 11/499: loss=2887.9127624080747, w0=8.4, w1=2.365347104292888\n",
      "SGD iter. 12/499: loss=4546.478384642151, w0=9.1, w1=2.6301322134836562\n",
      "SGD iter. 13/499: loss=2685.4431063082657, w0=9.799999999999999, w1=1.5926180196701156\n",
      "SGD iter. 14/499: loss=6034.179223837815, w0=10.499999999999998, w1=1.8369307433792499\n",
      "SGD iter. 15/499: loss=2265.9458345842127, w0=11.199999999999998, w1=1.0425613988884694\n",
      "SGD iter. 16/499: loss=2180.2096706583884, w0=11.899999999999997, w1=0.47260127435248356\n",
      "SGD iter. 17/499: loss=2284.307318716243, w0=12.599999999999996, w1=0.12742418662748523\n",
      "SGD iter. 18/499: loss=2329.039154388592, w0=13.299999999999995, w1=-0.5509228093470577\n",
      "SGD iter. 19/499: loss=6421.6734402295515, w0=13.999999999999995, w1=0.24424691577028945\n",
      "SGD iter. 20/499: loss=9106.33001194259, w0=14.699999999999994, w1=1.3693768759005964\n",
      "SGD iter. 21/499: loss=1618.9043470427075, w0=15.399999999999993, w1=0.6352625528996074\n",
      "SGD iter. 22/499: loss=2600.8288785428554, w0=16.099999999999994, w1=0.26934182216921015\n",
      "SGD iter. 23/499: loss=2261.128496891664, w0=16.799999999999994, w1=0.11888514571808265\n",
      "SGD iter. 24/499: loss=5416.247723245283, w0=17.499999999999993, w1=1.024060248905146\n",
      "SGD iter. 25/499: loss=5318.852687876166, w0=18.199999999999992, w1=1.3720272952955608\n",
      "SGD iter. 26/499: loss=3009.2185025474287, w0=18.89999999999999, w1=1.3373364359540896\n",
      "SGD iter. 27/499: loss=4201.937737828691, w0=19.59999999999999, w1=2.28424869769652\n",
      "SGD iter. 28/499: loss=1836.5971587168297, w0=20.29999999999999, w1=1.888811905753514\n",
      "SGD iter. 29/499: loss=3404.3093385752927, w0=20.99999999999999, w1=1.915184556378335\n",
      "SGD iter. 30/499: loss=1522.2649638608555, w0=21.69999999999999, w1=1.2941329828077415\n",
      "SGD iter. 31/499: loss=1983.905848142081, w0=22.399999999999988, w1=0.9185471445211717\n",
      "SGD iter. 32/499: loss=1872.612533026675, w0=23.099999999999987, w1=0.17921434507722767\n",
      "SGD iter. 33/499: loss=4638.968682659525, w0=23.799999999999986, w1=0.8221440438410232\n",
      "SGD iter. 34/499: loss=1330.8094159510686, w0=24.499999999999986, w1=-0.20478815375151038\n",
      "SGD iter. 35/499: loss=5307.36069468399, w0=25.199999999999985, w1=1.0012281360189366\n",
      "SGD iter. 36/499: loss=1092.9215946522593, w0=25.899999999999984, w1=0.4962104041946144\n",
      "SGD iter. 37/499: loss=790.7282369883576, w0=26.599999999999984, w1=-0.23790391880637463\n",
      "SGD iter. 38/499: loss=2355.414268663869, w0=27.299999999999983, w1=-0.2703329265737344\n",
      "SGD iter. 39/499: loss=6743.249071145664, w0=27.999999999999982, w1=1.2697294118134514\n",
      "SGD iter. 40/499: loss=3983.9694684589667, w0=28.69999999999998, w1=1.8106864637845936\n",
      "SGD iter. 41/499: loss=3174.9294704059557, w0=29.39999999999998, w1=2.4246008771621765\n",
      "SGD iter. 42/499: loss=1986.2451584713708, w0=30.09999999999998, w1=3.030004028606161\n",
      "SGD iter. 43/499: loss=3597.210186291017, w0=30.79999999999998, w1=3.761968622113796\n",
      "SGD iter. 44/499: loss=1141.9748588004918, w0=31.49999999999998, w1=2.7350364245212626\n",
      "SGD iter. 45/499: loss=1807.7093600335884, w0=32.19999999999998, w1=2.8673599508751013\n",
      "SGD iter. 46/499: loss=3898.9520182609363, w0=32.899999999999984, w1=4.230111346266848\n",
      "SGD iter. 47/499: loss=2200.4736651001904, w0=33.59999999999999, w1=5.177023608009279\n",
      "SGD iter. 48/499: loss=641.5492171897488, w0=34.29999999999999, w1=4.442909285008289\n",
      "SGD iter. 49/499: loss=2422.934168639828, w0=34.99999999999999, w1=5.188894938595686\n",
      "SGD iter. 50/499: loss=1393.9102378558134, w0=35.699999999999996, w1=5.088617839355477\n",
      "SGD iter. 51/499: loss=2727.35968135811, w0=36.4, w1=5.8205824328631115\n",
      "SGD iter. 52/499: loss=1591.2845608482214, w0=37.1, w1=6.316208693331944\n",
      "SGD iter. 53/499: loss=2511.893668273582, w0=37.800000000000004, w1=6.857165745303087\n",
      "SGD iter. 54/499: loss=2084.4251101855516, w0=38.50000000000001, w1=7.941041141994389\n",
      "SGD iter. 55/499: loss=625.4828895040558, w0=39.20000000000001, w1=7.371081017458403\n",
      "SGD iter. 56/499: loss=1488.5251732514016, w0=39.90000000000001, w1=8.002246357453256\n",
      "SGD iter. 57/499: loss=944.772796899989, w0=40.600000000000016, w1=8.425787610507271\n",
      "SGD iter. 58/499: loss=714.8126089672774, w0=41.30000000000002, w1=7.654964544439084\n",
      "SGD iter. 59/499: loss=1941.6458275771545, w0=42.00000000000002, w1=7.899277268148218\n",
      "SGD iter. 60/499: loss=860.6158776361192, w0=42.700000000000024, w1=7.905705149026565\n",
      "SGD iter. 61/499: loss=1306.4879012811928, w0=43.40000000000003, w1=8.102225231805066\n",
      "SGD iter. 62/499: loss=937.7912614230678, w0=44.10000000000003, w1=7.575036593057839\n",
      "SGD iter. 63/499: loss=1083.5837744384132, w0=44.80000000000003, w1=7.718367183652355\n",
      "SGD iter. 64/499: loss=322.9901974382363, w0=45.500000000000036, w1=7.333083043324227\n",
      "SGD iter. 65/499: loss=1436.1381941822144, w0=46.20000000000004, w1=7.529427636841455\n",
      "SGD iter. 66/499: loss=475.75854603853867, w0=46.90000000000004, w1=7.345266858523135\n",
      "SGD iter. 67/499: loss=456.83398796407954, w0=47.600000000000044, w1=6.491420588097866\n",
      "SGD iter. 68/499: loss=1111.6497734677894, w0=48.30000000000005, w1=7.105335001475449\n",
      "SGD iter. 69/499: loss=883.3392382063535, w0=49.00000000000005, w1=7.736500341470302\n",
      "SGD iter. 70/499: loss=783.1475026136312, w0=49.70000000000005, w1=7.879830932064818\n",
      "SGD iter. 71/499: loss=872.0353826829532, w0=50.400000000000055, w1=8.045283723997445\n",
      "SGD iter. 72/499: loss=759.4060891913961, w0=51.10000000000006, w1=7.804303809330796\n",
      "SGD iter. 73/499: loss=145.6238369926771, w0=51.80000000000006, w1=7.299286077506474\n",
      "SGD iter. 74/499: loss=627.201310464802, w0=52.500000000000064, w1=7.31459374421861\n",
      "SGD iter. 75/499: loss=9653.886136957515, w0=53.20000000000007, w1=4.54429404732962\n",
      "SGD iter. 76/499: loss=731.1514282977627, w0=53.90000000000007, w1=5.245228044764373\n",
      "SGD iter. 77/499: loss=7193.025465016493, w0=54.60000000000007, w1=1.8720843671746956\n",
      "SGD iter. 78/499: loss=118.59214548979546, w0=55.300000000000075, w1=1.7515798156956532\n",
      "SGD iter. 79/499: loss=48.36982700832238, w0=56.00000000000008, w1=1.5075529909865024\n",
      "SGD iter. 80/499: loss=0.008855948432433643, w0=55.300000000000075, w1=2.0547152932203727\n",
      "SGD iter. 81/499: loss=575.5011648098705, w0=56.00000000000008, w1=2.0920026048382425\n",
      "SGD iter. 82/499: loss=776.4079751052087, w0=56.70000000000008, w1=2.711136000782909\n",
      "SGD iter. 83/499: loss=557.1351531866434, w0=57.400000000000084, w1=2.907656083561412\n",
      "SGD iter. 84/499: loss=889.1569599438543, w0=58.10000000000009, w1=3.5538033169486325\n",
      "SGD iter. 85/499: loss=107.26794148930165, w0=58.80000000000009, w1=2.8144705175046885\n",
      "SGD iter. 86/499: loss=1.1831252270430928, w0=58.10000000000009, w1=3.7912679964466074\n",
      "SGD iter. 87/499: loss=140.19402766436767, w0=58.80000000000009, w1=3.969620117826422\n",
      "SGD iter. 88/499: loss=687.567143447033, w0=59.50000000000009, w1=4.180784512392625\n",
      "SGD iter. 89/499: loss=26.7335344851895, w0=60.200000000000095, w1=3.7497738276440113\n",
      "SGD iter. 90/499: loss=49.22285526207116, w0=59.50000000000009, w1=4.585812684916827\n",
      "SGD iter. 91/499: loss=32.33924019251651, w0=60.200000000000095, w1=3.9820466149503133\n",
      "SGD iter. 92/499: loss=133.99433895970824, w0=60.9000000000001, w1=3.645683657274237\n",
      "SGD iter. 93/499: loss=75.47976729023401, w0=60.200000000000095, w1=4.771616070775408\n",
      "SGD iter. 94/499: loss=2.782277152580838, w0=60.9000000000001, w1=4.24465903500656\n",
      "SGD iter. 95/499: loss=0.004020626483119766, w0=61.6000000000001, w1=3.587778067253596\n",
      "SGD iter. 96/499: loss=1001.0318716157243, w0=62.300000000000104, w1=4.950529462645343\n",
      "SGD iter. 97/499: loss=550.5155079021783, w0=63.00000000000011, w1=5.474710014097061\n",
      "SGD iter. 98/499: loss=81.80345095937638, w0=63.70000000000011, w1=4.947521375349834\n",
      "SGD iter. 99/499: loss=0.7825769726907565, w0=64.4000000000001, w1=4.5907958569939975\n",
      "SGD iter. 100/499: loss=5063.481368828437, w0=65.10000000000011, w1=1.2176521794043205\n",
      "SGD iter. 101/499: loss=506.7383429612605, w0=65.80000000000011, w1=1.4619649031134547\n",
      "SGD iter. 102/499: loss=602.3383711103429, w0=66.50000000000011, w1=2.6302957036309236\n",
      "SGD iter. 103/499: loss=535.0899735036402, w0=67.20000000000012, w1=2.9782627500213383\n",
      "SGD iter. 104/499: loss=495.4648139549283, w0=67.90000000000012, w1=3.326229796411753\n",
      "SGD iter. 105/499: loss=142.3230795890389, w0=67.20000000000012, w1=4.269736279948873\n",
      "SGD iter. 106/499: loss=424.2512005996327, w0=67.90000000000012, w1=4.822942196024986\n",
      "SGD iter. 107/499: loss=44.50542393848167, w0=68.60000000000012, w1=5.177969673554812\n",
      "SGD iter. 108/499: loss=26.52955706823307, w0=67.90000000000012, w1=5.421996498263963\n",
      "SGD iter. 109/499: loss=125.66944501158846, w0=68.60000000000012, w1=5.459283809881832\n",
      "SGD iter. 110/499: loss=64.30600241600678, w0=69.30000000000013, w1=6.116466513076817\n",
      "SGD iter. 111/499: loss=310.50368398511694, w0=70.00000000000013, w1=7.209091027402612\n",
      "SGD iter. 112/499: loss=52.73589435892606, w0=69.30000000000013, w1=7.714108759226934\n",
      "SGD iter. 113/499: loss=15.58815233936465, w0=70.00000000000013, w1=7.5306429801765145\n",
      "SGD iter. 114/499: loss=173.52547323726316, w0=70.70000000000013, w1=8.162917408658204\n",
      "SGD iter. 115/499: loss=52.908262755289435, w0=70.00000000000013, w1=8.667935140482527\n",
      "SGD iter. 116/499: loss=210.9585909223129, w0=70.70000000000013, w1=9.386098464513715\n",
      "SGD iter. 117/499: loss=0.9863419551060303, w0=71.40000000000013, w1=9.275924347632975\n",
      "SGD iter. 118/499: loss=83.0574977556755, w0=72.10000000000014, w1=10.333839654460533\n",
      "SGD iter. 119/499: loss=0.032732916423387645, w0=71.40000000000013, w1=11.187685924885802\n",
      "SGD iter. 120/499: loss=16.72357662760083, w0=72.10000000000014, w1=11.276213438374928\n",
      "SGD iter. 121/499: loss=52.01519574693029, w0=71.40000000000013, w1=11.716408693081899\n",
      "SGD iter. 122/499: loss=16.181154179844032, w0=72.10000000000014, w1=11.804936206571025\n",
      "SGD iter. 123/499: loss=0.0006837058365715193, w0=71.40000000000013, w1=11.915110323451765\n",
      "SGD iter. 124/499: loss=0.18129051560819917, w0=70.70000000000013, w1=11.56008284592194\n",
      "SGD iter. 125/499: loss=10.739919132324806, w0=71.40000000000013, w1=11.005975771925359\n",
      "SGD iter. 126/499: loss=16.742521308429115, w0=70.70000000000013, w1=11.662856739678322\n",
      "SGD iter. 127/499: loss=178.74653788425752, w0=71.40000000000013, w1=12.326001056721369\n",
      "SGD iter. 128/499: loss=4.5207039329261995, w0=70.70000000000013, w1=12.510161835039689\n",
      "SGD iter. 129/499: loss=3.1023392871075433, w0=70.00000000000013, w1=13.053178296404788\n",
      "SGD iter. 130/499: loss=23.154986981976318, w0=70.70000000000013, w1=14.415929691796535\n",
      "SGD iter. 131/499: loss=0.0473106987917673, w0=71.40000000000013, w1=13.472423208259414\n",
      "SGD iter. 132/499: loss=22.121072914831146, w0=70.70000000000013, w1=14.09723930807036\n",
      "SGD iter. 133/499: loss=9.643790644941065, w0=70.00000000000013, w1=14.217743859549403\n",
      "SGD iter. 134/499: loss=0.027560571247884087, w0=70.70000000000013, w1=14.552971914852657\n",
      "SGD iter. 135/499: loss=1.0615967543635894, w0=71.40000000000013, w1=15.458147018039721\n",
      "SGD iter. 136/499: loss=0.03215801060529005, w0=72.10000000000014, w1=15.087878927510925\n",
      "SGD iter. 137/499: loss=0.07123700988174973, w0=71.40000000000013, w1=15.989511191923683\n",
      "SGD iter. 138/499: loss=11.598524126938159, w0=72.10000000000014, w1=17.001949529790103\n",
      "SGD iter. 139/499: loss=40.875592122582844, w0=72.80000000000014, w1=17.039236841407973\n",
      "SGD iter. 140/499: loss=94.48023412069281, w0=73.50000000000014, w1=16.639779069021394\n",
      "SGD iter. 141/499: loss=109.7831523025248, w0=72.80000000000014, w1=15.692866807278964\n",
      "SGD iter. 142/499: loss=3.8553305455341746, w0=73.50000000000014, w1=15.33975105571165\n",
      "SGD iter. 143/499: loss=2.144303711377888, w0=74.20000000000014, w1=15.428278569200776\n",
      "SGD iter. 144/499: loss=7.517837702972445, w0=73.50000000000014, w1=16.08515953695374\n",
      "SGD iter. 145/499: loss=0.0003491865014638259, w0=72.80000000000014, w1=15.251821954394163\n",
      "SGD iter. 146/499: loss=26.45288316294086, w0=72.10000000000014, w1=15.598905940014154\n",
      "SGD iter. 147/499: loss=189.2963376009273, w0=72.80000000000014, w1=16.838222240992156\n",
      "SGD iter. 148/499: loss=4.564126647868348, w0=73.50000000000014, w1=16.038391506929447\n",
      "SGD iter. 149/499: loss=37.57596251355641, w0=72.80000000000014, w1=16.383568594654445\n",
      "SGD iter. 150/499: loss=1.6803843892220331, w0=72.10000000000014, w1=16.733905528022838\n",
      "SGD iter. 151/499: loss=0.1772067465831567, w0=71.40000000000013, w1=17.08424246139123\n",
      "SGD iter. 152/499: loss=2.294946214465146, w0=72.10000000000014, w1=16.879408941516008\n",
      "SGD iter. 153/499: loss=7.161008642069323, w0=71.40000000000013, w1=17.302648366288523\n",
      "SGD iter. 154/499: loss=78.34798159666015, w0=72.10000000000014, w1=17.416468693102836\n",
      "SGD iter. 155/499: loss=28.170332666370943, w0=72.80000000000014, w1=17.96967460917895\n",
      "SGD iter. 156/499: loss=0.13987789734800915, w0=73.50000000000014, w1=17.764841089303726\n",
      "SGD iter. 157/499: loss=5.414220744600734, w0=72.80000000000014, w1=18.377639260305138\n",
      "SGD iter. 158/499: loss=7.966954159805167, w0=72.10000000000014, w1=17.652619070224333\n",
      "SGD iter. 159/499: loss=35.43290737948215, w0=72.80000000000014, w1=17.678991720849154\n",
      "SGD iter. 160/499: loss=19.360903995802975, w0=73.50000000000014, w1=18.232197636925267\n",
      "SGD iter. 161/499: loss=159.56390760292666, w0=72.80000000000014, w1=17.285285375182838\n",
      "SGD iter. 162/499: loss=107.78260045353342, w0=72.10000000000014, w1=16.736890871425025\n",
      "SGD iter. 163/499: loss=152.69182278998778, w0=71.40000000000013, w1=16.750646067400517\n",
      "SGD iter. 164/499: loss=154.2414990620733, w0=72.10000000000014, w1=17.989962368378517\n",
      "SGD iter. 165/499: loss=1.1871029618761464, w0=72.80000000000014, w1=17.44694590701342\n",
      "SGD iter. 166/499: loss=0.9689491728098498, w0=72.10000000000014, w1=17.886634312098604\n",
      "SGD iter. 167/499: loss=72.06337806381545, w0=71.40000000000013, w1=17.625922090716738\n",
      "SGD iter. 168/499: loss=53.773540896072376, w0=72.10000000000014, w1=17.89140579294097\n",
      "SGD iter. 169/499: loss=14523.305085536564, w0=72.80000000000014, w1=15.12110609605198\n",
      "SGD iter. 170/499: loss=64.76812330716986, w0=72.10000000000014, w1=15.599154298478103\n",
      "SGD iter. 171/499: loss=24.003086040869615, w0=71.40000000000013, w1=16.01022948302033\n",
      "SGD iter. 172/499: loss=12.497415596645586, w0=70.70000000000013, w1=16.4504247377273\n",
      "SGD iter. 173/499: loss=0.04982775377398667, w0=71.40000000000013, w1=15.642310996685367\n",
      "SGD iter. 174/499: loss=0.0714396694348031, w0=70.70000000000013, w1=15.992647930053758\n",
      "SGD iter. 175/499: loss=0.5337837817421288, w0=70.00000000000013, w1=15.11291780022128\n",
      "SGD iter. 176/499: loss=28.686258635356836, w0=69.30000000000013, w1=14.852205578839417\n",
      "SGD iter. 177/499: loss=128.81983645140147, w0=70.00000000000013, w1=14.96602590565373\n",
      "SGD iter. 178/499: loss=14.663158380360832, w0=70.70000000000013, w1=15.16846279569473\n",
      "SGD iter. 179/499: loss=0.038245988768070165, w0=71.40000000000013, w1=14.818125862326339\n",
      "SGD iter. 180/499: loss=5.394986235458767, w0=72.10000000000014, w1=14.783435002984868\n",
      "SGD iter. 181/499: loss=15.93236713283431, w0=71.40000000000013, w1=13.6151042024674\n",
      "SGD iter. 182/499: loss=0.03302982317197996, w0=72.10000000000014, w1=13.657430759070891\n",
      "SGD iter. 183/499: loss=26.323212544632526, w0=72.80000000000014, w1=13.853950841849393\n",
      "SGD iter. 184/499: loss=11533.732982877822, w0=73.50000000000014, w1=10.480807164259716\n",
      "SGD iter. 185/499: loss=4.860737828607833, w0=74.20000000000014, w1=10.824519785443107\n",
      "SGD iter. 186/499: loss=18.594898721149704, w0=74.90000000000015, w1=10.474581853962789\n",
      "SGD iter. 187/499: loss=4.456949508269147, w0=75.60000000000015, w1=11.208857597454589\n",
      "SGD iter. 188/499: loss=54.832833932944446, w0=76.30000000000015, w1=12.5742270501182\n",
      "SGD iter. 189/499: loss=14.09415512728397, w0=77.00000000000016, w1=13.098407601569917\n",
      "SGD iter. 190/499: loss=112.173940842173, w0=76.30000000000015, w1=13.248864278021045\n",
      "SGD iter. 191/499: loss=103.46254328812468, w0=75.60000000000015, w1=13.689059532728017\n",
      "SGD iter. 192/499: loss=1.0711241336203345, w0=74.90000000000015, w1=13.1593585586659\n",
      "SGD iter. 193/499: loss=18.02183448397178, w0=75.60000000000015, w1=13.312252315780482\n",
      "SGD iter. 194/499: loss=12.332866539438312, w0=76.30000000000015, w1=13.465146072895063\n",
      "SGD iter. 195/499: loss=93.693384327428, w0=75.60000000000015, w1=13.266385207076539\n",
      "SGD iter. 196/499: loss=28.46520185923244, w0=74.90000000000015, w1=13.697395891825153\n",
      "SGD iter. 197/499: loss=25.485974955980716, w0=75.60000000000015, w1=13.347457960344835\n",
      "SGD iter. 198/499: loss=70.2378605444945, w0=74.90000000000015, w1=14.050962878735698\n",
      "SGD iter. 199/499: loss=10.169193429799723, w0=75.60000000000015, w1=14.674451001021875\n",
      "SGD iter. 200/499: loss=5.292629146615356, w0=76.30000000000015, w1=15.406415594529511\n",
      "SGD iter. 201/499: loss=86.8447485348409, w0=75.60000000000015, w1=15.228063473149696\n",
      "SGD iter. 202/499: loss=12369.167822470055, w0=76.30000000000015, w1=11.854919795560019\n",
      "SGD iter. 203/499: loss=40.23104934318424, w0=77.00000000000016, w1=12.066084190126222\n",
      "SGD iter. 204/499: loss=3.1148294070654448, w0=77.70000000000016, w1=12.712231423513444\n",
      "SGD iter. 205/499: loss=2.990797432691855, w0=77.00000000000016, w1=13.04859438118952\n",
      "SGD iter. 206/499: loss=4.240418474106391, w0=77.70000000000016, w1=14.061032719055941\n",
      "SGD iter. 207/499: loss=9.737959431382748, w0=78.40000000000016, w1=13.661574946669361\n",
      "SGD iter. 208/499: loss=5.0079551696574205, w0=77.70000000000016, w1=14.245887484215253\n",
      "SGD iter. 209/499: loss=16.22180983234417, w0=77.00000000000016, w1=13.40469731599061\n",
      "SGD iter. 210/499: loss=13.561911891559241, w0=76.30000000000015, w1=12.32082191929931\n",
      "SGD iter. 211/499: loss=4.292234434096578, w0=77.00000000000016, w1=12.748339004516728\n",
      "SGD iter. 212/499: loss=4.335626732215299, w0=76.30000000000015, w1=13.30244607851331\n",
      "SGD iter. 213/499: loss=12.549953962283686, w0=75.60000000000015, w1=12.107707241408884\n",
      "SGD iter. 214/499: loss=150.95751577910417, w0=76.30000000000015, w1=13.28851194210878\n",
      "SGD iter. 215/499: loss=4.821132055629406, w0=75.60000000000015, w1=12.082495652338332\n",
      "SGD iter. 216/499: loss=0.04758966500737253, w0=74.90000000000015, w1=11.336509998750936\n",
      "SGD iter. 217/499: loss=0.49337567123549925, w0=74.20000000000014, w1=11.519975777801355\n",
      "SGD iter. 218/499: loss=28.124848168031345, w0=74.90000000000015, w1=11.672869534915936\n",
      "SGD iter. 219/499: loss=77.39816068543254, w0=74.20000000000014, w1=11.823326211367064\n",
      "SGD iter. 220/499: loss=69.91111407922254, w0=73.50000000000014, w1=11.217923059923079\n",
      "SGD iter. 221/499: loss=10.26136639498295, w0=74.20000000000014, w1=12.301798456614382\n",
      "SGD iter. 222/499: loss=4.286684601305038, w0=74.90000000000015, w1=13.026818646695185\n",
      "SGD iter. 223/499: loss=6.237387654435259, w0=74.20000000000014, w1=13.797641712763372\n",
      "SGD iter. 224/499: loss=7.495725511795497, w0=73.50000000000014, w1=14.597472446826082\n",
      "SGD iter. 225/499: loss=108.9565244592683, w0=72.80000000000014, w1=14.86895262880866\n",
      "SGD iter. 226/499: loss=205.9468312682983, w0=73.50000000000014, w1=16.10826892978666\n",
      "SGD iter. 227/499: loss=21.25890875353153, w0=74.20000000000014, w1=16.134641580411483\n",
      "SGD iter. 228/499: loss=32.40217811266634, w0=73.50000000000014, w1=16.686613012349163\n",
      "SGD iter. 229/499: loss=8.295515070157963, w0=74.20000000000014, w1=16.883133095127665\n",
      "SGD iter. 230/499: loss=53.05664393588515, w0=73.50000000000014, w1=15.826731863748774\n",
      "SGD iter. 231/499: loss=9.069407561668209, w0=74.20000000000014, w1=16.29331398971535\n",
      "SGD iter. 232/499: loss=105.15813257771848, w0=74.90000000000015, w1=15.674172834300968\n",
      "SGD iter. 233/499: loss=49.47463229670298, w0=74.20000000000014, w1=16.02125681992096\n",
      "SGD iter. 234/499: loss=1.2380676997449798, w0=74.90000000000015, w1=16.673313717363417\n",
      "SGD iter. 235/499: loss=59.64220248164088, w0=74.20000000000014, w1=16.823770393814545\n",
      "SGD iter. 236/499: loss=9.344210181704113, w0=73.50000000000014, w1=17.557884716815533\n",
      "SGD iter. 237/499: loss=2.7305772914049444, w0=74.20000000000014, w1=16.614378233278412\n",
      "SGD iter. 238/499: loss=48.06062975656755, w0=73.50000000000014, w1=17.122879351018245\n",
      "SGD iter. 239/499: loss=153.46623465696067, w0=72.80000000000014, w1=17.06656973597294\n",
      "SGD iter. 240/499: loss=0.10356419457752343, w0=73.50000000000014, w1=17.445109519329673\n",
      "SGD iter. 241/499: loss=30.305562634181715, w0=74.20000000000014, w1=16.87209943631505\n",
      "SGD iter. 242/499: loss=23.63172870029241, w0=74.90000000000015, w1=17.41305648828619\n",
      "SGD iter. 243/499: loss=0.00010638448715965135, w0=74.20000000000014, w1=17.78864232657276\n",
      "SGD iter. 244/499: loss=2.9993937871688052, w0=73.50000000000014, w1=18.59675606761469\n",
      "SGD iter. 245/499: loss=1.1360797437701655, w0=72.80000000000014, w1=18.54459572208498\n",
      "SGD iter. 246/499: loss=7.2728081528405095, w0=73.50000000000014, w1=18.169009883798413\n",
      "SGD iter. 247/499: loss=81.95823956083295, w0=72.80000000000014, w1=18.440490065780992\n",
      "SGD iter. 248/499: loss=8.519294318962265, w0=72.10000000000014, w1=17.561317753550185\n",
      "SGD iter. 249/499: loss=1.5544050414258743, w0=72.80000000000014, w1=17.542738294651308\n",
      "SGD iter. 250/499: loss=59.79441047930675, w0=73.50000000000014, w1=17.739082888168536\n",
      "SGD iter. 251/499: loss=0.2044321851783241, w0=74.20000000000014, w1=18.371357316650226\n",
      "SGD iter. 252/499: loss=65.36609096006642, w0=74.90000000000015, w1=18.02141938516991\n",
      "SGD iter. 253/499: loss=6.638778229795504, w0=74.20000000000014, w1=18.371756318538303\n",
      "SGD iter. 254/499: loss=13.849676014295312, w0=73.50000000000014, w1=18.083259053980886\n",
      "SGD iter. 255/499: loss=9.265704644624572, w0=72.80000000000014, w1=17.83297793751883\n",
      "SGD iter. 256/499: loss=1.958413655174942, w0=72.10000000000014, w1=16.999640354959254\n",
      "SGD iter. 257/499: loss=24.710452480962378, w0=71.40000000000013, w1=15.636888959567507\n",
      "SGD iter. 258/499: loss=67.0002960343491, w0=72.10000000000014, w1=15.20655737110677\n",
      "SGD iter. 259/499: loss=4.2781060110437705, w0=71.40000000000013, w1=15.39071814942509\n",
      "SGD iter. 260/499: loss=16.849796155710887, w0=70.70000000000013, w1=14.733535446230105\n",
      "SGD iter. 261/499: loss=0.34658725042432814, w0=70.00000000000013, w1=15.17322385131529\n",
      "SGD iter. 262/499: loss=114.19373152877145, w0=70.70000000000013, w1=14.823285919834973\n",
      "SGD iter. 263/499: loss=233.89993752659925, w0=71.40000000000013, w1=15.94841587996528\n",
      "SGD iter. 264/499: loss=35.083650864136196, w0=72.10000000000014, w1=16.113868671897905\n",
      "SGD iter. 265/499: loss=33.81787614364395, w0=72.80000000000014, w1=15.540858588883282\n",
      "SGD iter. 266/499: loss=5.305986262279485, w0=72.10000000000014, w1=14.948540627615104\n",
      "SGD iter. 267/499: loss=4.563517470968383, w0=71.40000000000013, w1=15.132701405933425\n",
      "SGD iter. 268/499: loss=16.703587373453377, w0=70.70000000000013, w1=15.572896660640396\n",
      "SGD iter. 269/499: loss=61.929414805605845, w0=71.40000000000013, w1=15.610183972258266\n",
      "SGD iter. 270/499: loss=28.091306319676256, w0=72.10000000000014, w1=16.233672094544442\n",
      "SGD iter. 271/499: loss=7.9406904926914965, w0=72.80000000000014, w1=16.879819327931664\n",
      "SGD iter. 272/499: loss=49.51336720695483, w0=73.50000000000014, w1=18.06062402863156\n",
      "SGD iter. 273/499: loss=0.1949708901819982, w0=72.80000000000014, w1=18.1707981455123\n",
      "SGD iter. 274/499: loss=0.2604734341504484, w0=73.50000000000014, w1=18.822855042954757\n",
      "SGD iter. 275/499: loss=9.760560720983175, w0=74.20000000000014, w1=17.696922629453585\n",
      "SGD iter. 276/499: loss=71.66540825249739, w0=73.50000000000014, w1=17.97685162189005\n",
      "SGD iter. 277/499: loss=53.37961333080686, w0=72.80000000000014, w1=18.1941086260698\n",
      "SGD iter. 278/499: loss=11.57486158596054, w0=72.10000000000014, w1=18.75223232981884\n",
      "SGD iter. 279/499: loss=3.3039564842242455, w0=72.80000000000014, w1=18.717541470477368\n",
      "SGD iter. 280/499: loss=14.197980404887295, w0=72.10000000000014, w1=19.128616655019595\n",
      "SGD iter. 281/499: loss=61.910037700646185, w0=72.80000000000014, w1=18.574509581023015\n",
      "SGD iter. 282/499: loss=3.0809063604148847, w0=73.50000000000014, w1=18.66303709451214\n",
      "SGD iter. 283/499: loss=47.580570686230246, w0=72.80000000000014, w1=19.343636272168226\n",
      "SGD iter. 284/499: loss=139.33793121197579, w0=73.50000000000014, w1=18.65694163666209\n",
      "SGD iter. 285/499: loss=15.767113633262186, w0=72.80000000000014, w1=19.09713689136906\n",
      "SGD iter. 286/499: loss=24.575600351554648, w0=72.10000000000014, w1=18.25594672314442\n",
      "SGD iter. 287/499: loss=0.12727446928419026, w0=72.80000000000014, w1=19.112168775648957\n",
      "SGD iter. 288/499: loss=51.22566439967096, w0=73.50000000000014, w1=19.22598910246327\n",
      "SGD iter. 289/499: loss=1.230153627562875, w0=74.20000000000014, w1=18.337157278296775\n",
      "SGD iter. 290/499: loss=22.130962117271896, w0=73.50000000000014, w1=17.71802388235211\n",
      "SGD iter. 291/499: loss=22.421618421715195, w0=74.20000000000014, w1=18.33101637953567\n",
      "SGD iter. 292/499: loss=89.66318128377235, w0=73.50000000000014, w1=17.27461514815678\n",
      "SGD iter. 293/499: loss=78.36467544027406, w0=74.20000000000014, w1=17.622582194547196\n",
      "SGD iter. 294/499: loss=35.72134258920249, w0=73.50000000000014, w1=18.007866334875324\n",
      "SGD iter. 295/499: loss=45.45085027532592, w0=72.80000000000014, w1=17.30693233744057\n",
      "SGD iter. 296/499: loss=90.9413559260055, w0=73.50000000000014, w1=17.654899383830987\n",
      "SGD iter. 297/499: loss=1.2167364233138973, w0=72.80000000000014, w1=16.642461045964566\n",
      "SGD iter. 298/499: loss=22.977545553166454, w0=72.10000000000014, w1=16.925008865050792\n",
      "SGD iter. 299/499: loss=0.3947911937129617, w0=71.40000000000013, w1=17.350795012341532\n",
      "SGD iter. 300/499: loss=2.8594573253827757, w0=70.70000000000013, w1=17.774034437114047\n",
      "SGD iter. 301/499: loss=56.04167068763827, w0=71.40000000000013, w1=18.387026934297605\n",
      "SGD iter. 302/499: loss=0.24186644454917816, w0=72.10000000000014, w1=18.896212778243857\n",
      "SGD iter. 303/499: loss=21.5148186726299, w0=72.80000000000014, w1=17.9945805138311\n",
      "SGD iter. 304/499: loss=4.190527372493901, w0=73.50000000000014, w1=18.637510212594893\n",
      "SGD iter. 305/499: loss=24.071582075558737, w0=74.20000000000014, w1=18.674797524212764\n",
      "SGD iter. 306/499: loss=17.100254533404037, w0=74.90000000000015, w1=18.940281226436994\n",
      "SGD iter. 307/499: loss=122.95556850712842, w0=74.20000000000014, w1=17.883879995058106\n",
      "SGD iter. 308/499: loss=18.6016504113306, w0=73.50000000000014, w1=18.435851426995786\n",
      "SGD iter. 309/499: loss=44.18787614090287, w0=74.20000000000014, w1=17.851538889449895\n",
      "SGD iter. 310/499: loss=17.97878854340497, w0=74.90000000000015, w1=17.51517593177382\n",
      "SGD iter. 311/499: loss=5.292283021919133, w0=74.20000000000014, w1=18.333834301579447\n",
      "SGD iter. 312/499: loss=0.14875582990282696, w0=74.90000000000015, w1=18.422361815068573\n",
      "SGD iter. 313/499: loss=87.42466353711156, w0=74.20000000000014, w1=18.447659580457415\n",
      "SGD iter. 314/499: loss=17.777967791655374, w0=74.90000000000015, w1=18.484946892075286\n",
      "SGD iter. 315/499: loss=14414.801499677866, w0=75.60000000000015, w1=15.714647195186297\n",
      "SGD iter. 316/499: loss=246.87504810927484, w0=74.90000000000015, w1=15.834539008674628\n",
      "SGD iter. 317/499: loss=5.237601775973177, w0=74.20000000000014, w1=15.109518818593825\n",
      "SGD iter. 318/499: loss=46.4066999000175, w0=73.50000000000014, w1=15.39206663768005\n",
      "SGD iter. 319/499: loss=77.26278655527585, w0=72.80000000000014, w1=14.445154375937621\n",
      "SGD iter. 320/499: loss=124.17807935178027, w0=73.50000000000014, w1=15.625959076637518\n",
      "SGD iter. 321/499: loss=0.007029719691511511, w0=72.80000000000014, w1=14.74678676440671\n",
      "SGD iter. 322/499: loss=55.93450996007207, w0=73.50000000000014, w1=14.007453964962767\n",
      "SGD iter. 323/499: loss=0.034915921044277126, w0=72.80000000000014, w1=14.611220034929282\n",
      "SGD iter. 324/499: loss=14.838889302308587, w0=73.50000000000014, w1=13.257263140896054\n",
      "SGD iter. 325/499: loss=26.965926313455775, w0=74.20000000000014, w1=13.294550452513924\n",
      "SGD iter. 326/499: loss=89.479638892541, w0=73.50000000000014, w1=13.511807456693674\n",
      "SGD iter. 327/499: loss=18.23652846465939, w0=74.20000000000014, w1=14.144081885175364\n",
      "SGD iter. 328/499: loss=29.61935924206132, w0=74.90000000000015, w1=13.40474908573142\n",
      "SGD iter. 329/499: loss=0.47736128158347935, w0=74.20000000000014, w1=12.876693270220771\n",
      "SGD iter. 330/499: loss=35.14645574675791, w0=74.90000000000015, w1=13.755941236116943\n",
      "SGD iter. 331/499: loss=2.7365258975594617, w0=74.20000000000014, w1=13.77452069501582\n",
      "SGD iter. 332/499: loss=13.121817628504964, w0=73.50000000000014, w1=14.205531379764434\n",
      "SGD iter. 333/499: loss=1.8550300588173132, w0=72.80000000000014, w1=14.999900724255214\n",
      "SGD iter. 334/499: loss=3.4067234383390006, w0=72.10000000000014, w1=14.407582762987037\n",
      "SGD iter. 335/499: loss=24.955775638107557, w0=71.40000000000013, w1=14.690130582073262\n",
      "SGD iter. 336/499: loss=34.44683518071301, w0=72.10000000000014, w1=15.156712708039837\n",
      "SGD iter. 337/499: loss=27.394364376884894, w0=71.40000000000013, w1=15.541996848367965\n",
      "SGD iter. 338/499: loss=89.77126195954047, w0=72.10000000000014, w1=14.85530221286183\n",
      "SGD iter. 339/499: loss=44.609415491624816, w0=71.40000000000013, w1=14.880599978250672\n",
      "SGD iter. 340/499: loss=21.567758974968953, w0=70.70000000000013, w1=15.438723681999711\n",
      "SGD iter. 341/499: loss=0.0011872656296457536, w0=70.00000000000013, w1=14.558993552167234\n",
      "SGD iter. 342/499: loss=1.2140006145540039, w0=69.30000000000013, w1=15.128953676703219\n",
      "SGD iter. 343/499: loss=9.20044985420842, w0=70.00000000000013, w1=15.748087072647886\n",
      "SGD iter. 344/499: loss=24.210082431143302, w0=70.70000000000013, w1=16.543256797765235\n",
      "SGD iter. 345/499: loss=18.186816922766663, w0=71.40000000000013, w1=16.792855260452413\n",
      "SGD iter. 346/499: loss=12.079804458508963, w0=72.10000000000014, w1=17.04245372313959\n",
      "SGD iter. 347/499: loss=16.411320750496646, w0=71.40000000000013, w1=17.589616025373463\n",
      "SGD iter. 348/499: loss=1.2302722906851686, w0=72.10000000000014, w1=17.641776370903173\n",
      "SGD iter. 349/499: loss=79.23773096635374, w0=72.80000000000014, w1=18.081700813787354\n",
      "SGD iter. 350/499: loss=109.86078550245733, w0=73.50000000000014, w1=17.69957482923702\n",
      "SGD iter. 351/499: loss=16.687337136089674, w0=72.80000000000014, w1=18.235094512063224\n",
      "SGD iter. 352/499: loss=82.3543950414787, w0=73.50000000000014, w1=18.58306155845364\n",
      "SGD iter. 353/499: loss=101.10583125491631, w0=74.20000000000014, w1=18.200935573903305\n",
      "SGD iter. 354/499: loss=25.681456881175976, w0=73.50000000000014, w1=18.823721980723597\n",
      "SGD iter. 355/499: loss=23.974349175459796, w0=74.20000000000014, w1=18.861009292341468\n",
      "SGD iter. 356/499: loss=105.61052333409997, w0=74.90000000000015, w1=19.205477539211934\n",
      "SGD iter. 357/499: loss=17182.760933787686, w0=75.60000000000015, w1=15.832333861622256\n",
      "SGD iter. 358/499: loss=29.329192063744117, w0=76.30000000000015, w1=15.482395930141939\n",
      "SGD iter. 359/499: loss=105.11007535528503, w0=75.60000000000015, w1=15.283635064323414\n",
      "SGD iter. 360/499: loss=60.26938283719662, w0=74.90000000000015, w1=15.835606496261093\n",
      "SGD iter. 361/499: loss=0.18183062434225175, w0=75.60000000000015, w1=15.978937086855609\n",
      "SGD iter. 362/499: loss=2.1897866358017732, w0=74.90000000000015, w1=16.354522925142177\n",
      "SGD iter. 363/499: loss=36.94303114234314, w0=74.20000000000014, w1=15.14850663537173\n",
      "SGD iter. 364/499: loss=11568.60674711617, w0=74.90000000000015, w1=12.378206938482741\n",
      "SGD iter. 365/499: loss=14.845894976747674, w0=74.20000000000014, w1=12.042978883179487\n",
      "SGD iter. 366/499: loss=160.76997500801778, w0=73.50000000000014, w1=11.986669268134182\n",
      "SGD iter. 367/499: loss=11.894607215915284, w0=74.20000000000014, w1=11.459480629386956\n",
      "SGD iter. 368/499: loss=49.02158090074328, w0=74.90000000000015, w1=11.573300956201269\n",
      "SGD iter. 369/499: loss=61.27365715999057, w0=75.60000000000015, w1=11.784465350767473\n",
      "SGD iter. 370/499: loss=110.72381142131378, w0=74.90000000000015, w1=12.336436782705151\n",
      "SGD iter. 371/499: loss=0.19728423646430673, w0=75.60000000000015, w1=12.424964296194277\n",
      "SGD iter. 372/499: loss=7.322331625212702, w0=74.90000000000015, w1=12.372803950664567\n",
      "SGD iter. 373/499: loss=34.35558963507211, w0=75.60000000000015, w1=13.252051916560738\n",
      "SGD iter. 374/499: loss=37.6528148069159, w0=76.30000000000015, w1=13.448396510077966\n",
      "SGD iter. 375/499: loss=25.14722090892451, w0=75.60000000000015, w1=13.44196862919962\n",
      "SGD iter. 376/499: loss=80.51388921874583, w0=74.90000000000015, w1=13.243207763381095\n",
      "SGD iter. 377/499: loss=30.948774363500593, w0=74.20000000000014, w1=14.186714246918216\n",
      "SGD iter. 378/499: loss=74.28835006170763, w0=73.50000000000014, w1=13.228579156016409\n",
      "SGD iter. 379/499: loss=120.32160423113298, w0=72.80000000000014, w1=13.500059337998987\n",
      "SGD iter. 380/499: loss=43.045775069200666, w0=73.50000000000014, w1=14.024239889450705\n",
      "SGD iter. 381/499: loss=42.45332134468265, w0=74.20000000000014, w1=13.783259974784057\n",
      "SGD iter. 382/499: loss=77.75309038392164, w0=73.50000000000014, w1=13.8085577401729\n",
      "SGD iter. 383/499: loss=87.95133361283895, w0=72.80000000000014, w1=13.203154588728914\n",
      "SGD iter. 384/499: loss=3.0144939018985006, w0=72.10000000000014, w1=12.707528328260082\n",
      "SGD iter. 385/499: loss=43.85294602400322, w0=72.80000000000014, w1=12.744815639877952\n",
      "SGD iter. 386/499: loss=67.11779768016387, w0=73.50000000000014, w1=12.858635966692265\n",
      "SGD iter. 387/499: loss=114.92767549742602, w0=72.80000000000014, w1=13.290428544975686\n",
      "SGD iter. 388/499: loss=207.8777698143666, w0=73.50000000000014, w1=13.634896791846154\n",
      "SGD iter. 389/499: loss=11.546588653151373, w0=72.80000000000014, w1=13.279869314316329\n",
      "SGD iter. 390/499: loss=40.35066019184861, w0=72.10000000000014, w1=13.430325990767457\n",
      "SGD iter. 391/499: loss=31.294556495315675, w0=72.80000000000014, w1=13.857843075984876\n",
      "SGD iter. 392/499: loss=33.16931580665457, w0=72.10000000000014, w1=14.482659175795822\n",
      "SGD iter. 393/499: loss=208.55075939360717, w0=72.80000000000014, w1=15.60778913592613\n",
      "SGD iter. 394/499: loss=5.979687022569756, w0=72.10000000000014, w1=14.976623795931276\n",
      "SGD iter. 395/499: loss=7.122080761025175, w0=72.80000000000014, w1=14.84960935070325\n",
      "SGD iter. 396/499: loss=11.00851511532612, w0=72.10000000000014, w1=15.66826772050888\n",
      "SGD iter. 397/499: loss=0.6290526561636597, w0=72.80000000000014, w1=16.28218213388646\n",
      "SGD iter. 398/499: loss=15.33738067893923, w0=72.10000000000014, w1=15.78655587341763\n",
      "SGD iter. 399/499: loss=65.01245487175534, w0=72.80000000000014, w1=16.44970019046068\n",
      "SGD iter. 400/499: loss=25.4794003045496, w0=73.50000000000014, w1=15.895593116464097\n",
      "SGD iter. 401/499: loss=6.684190250247436, w0=74.20000000000014, w1=16.511980065301348\n",
      "SGD iter. 402/499: loss=3.4402694422165676, w0=74.90000000000015, w1=16.978562191267923\n",
      "SGD iter. 403/499: loss=16.25488399449227, w0=74.20000000000014, w1=17.548522315803908\n",
      "SGD iter. 404/499: loss=195.94855983438194, w0=73.50000000000014, w1=17.668414129292238\n",
      "SGD iter. 405/499: loss=12.718523016693124, w0=74.20000000000014, w1=16.971829378051474\n",
      "SGD iter. 406/499: loss=41.49450832031511, w0=73.50000000000014, w1=15.765813088281027\n",
      "SGD iter. 407/499: loss=42.48292781089809, w0=72.80000000000014, w1=15.916269764732155\n",
      "SGD iter. 408/499: loss=6.804572386921936, w0=72.10000000000014, w1=16.650384087733144\n",
      "SGD iter. 409/499: loss=7.460059248580995, w0=72.80000000000014, w1=16.626418247930054\n",
      "SGD iter. 410/499: loss=12.66952005293096, w0=73.50000000000014, w1=17.344581571961243\n",
      "SGD iter. 411/499: loss=28.512890960996646, w0=74.20000000000014, w1=17.610065274185473\n",
      "SGD iter. 412/499: loss=20.888227596320156, w0=73.50000000000014, w1=16.76887510596083\n",
      "SGD iter. 413/499: loss=66.20535436512331, w0=72.80000000000014, w1=17.048804098397294\n",
      "SGD iter. 414/499: loss=19.620469226027414, w0=72.10000000000014, w1=16.693776620867467\n",
      "SGD iter. 415/499: loss=1.0475186904527163, w0=72.80000000000014, w1=17.20296246481372\n",
      "SGD iter. 416/499: loss=91.92975778952768, w0=73.50000000000014, w1=17.550929511204135\n",
      "SGD iter. 417/499: loss=2.2668917539283533, w0=74.20000000000014, w1=16.649297246791377\n",
      "SGD iter. 418/499: loss=14.254638957005334, w0=73.50000000000014, w1=16.38451213760061\n",
      "SGD iter. 419/499: loss=120.2887456116989, w0=74.20000000000014, w1=17.62382843857861\n",
      "SGD iter. 420/499: loss=1.2981738331034927, w0=73.50000000000014, w1=17.42139154853761\n",
      "SGD iter. 421/499: loss=2.5182056109023874, w0=74.20000000000014, w1=18.044879670823786\n",
      "SGD iter. 422/499: loss=10.95484992906497, w0=73.50000000000014, w1=17.596220632039074\n",
      "SGD iter. 423/499: loss=30.463086288065394, w0=72.80000000000014, w1=18.104721749778907\n",
      "SGD iter. 424/499: loss=21.164983470324888, w0=72.10000000000014, w1=17.50018964392475\n",
      "SGD iter. 425/499: loss=0.6512660200677296, w0=71.40000000000013, w1=18.070149768460734\n",
      "SGD iter. 426/499: loss=80.72572741346728, w0=72.10000000000014, w1=18.266494361977962\n",
      "SGD iter. 427/499: loss=1.8993790979520309, w0=72.80000000000014, w1=17.447835992172333\n",
      "SGD iter. 428/499: loss=17.479660414419236, w0=72.10000000000014, w1=17.11260793686908\n",
      "SGD iter. 429/499: loss=0.2443904537986518, w0=71.40000000000013, w1=17.552296341954264\n",
      "SGD iter. 430/499: loss=28.58896322537858, w0=70.70000000000013, w1=16.189544946562517\n",
      "SGD iter. 431/499: loss=123.27137081965785, w0=71.40000000000013, w1=15.450212147118574\n",
      "SGD iter. 432/499: loss=17.555657578214227, w0=70.70000000000013, w1=16.008335850867613\n",
      "SGD iter. 433/499: loss=6.558322904342833, w0=70.00000000000013, w1=14.813597013763188\n",
      "SGD iter. 434/499: loss=103.22997091872526, w0=70.70000000000013, w1=14.126902378257052\n",
      "SGD iter. 435/499: loss=26.235578066294476, w0=70.00000000000013, w1=14.962941235529868\n",
      "SGD iter. 436/499: loss=170.8271458563648, w0=70.70000000000013, w1=16.143745936229763\n",
      "SGD iter. 437/499: loss=3.6279437561177854, w0=70.00000000000013, w1=14.780994540838016\n",
      "SGD iter. 438/499: loss=47.18657128837888, w0=70.70000000000013, w1=15.208511626055435\n",
      "SGD iter. 439/499: loss=22.608300923333278, w0=71.40000000000013, w1=15.35184221664995\n",
      "SGD iter. 440/499: loss=2.441254311693158, w0=70.70000000000013, w1=15.747279008592956\n",
      "SGD iter. 441/499: loss=33.00734699944857, w0=70.00000000000013, w1=16.02720800102942\n",
      "SGD iter. 442/499: loss=129.59928881031965, w0=70.70000000000013, w1=16.238372395595622\n",
      "SGD iter. 443/499: loss=4.096507916006062, w0=71.40000000000013, w1=15.617320822025029\n",
      "SGD iter. 444/499: loss=0.04566549615174379, w0=72.10000000000014, w1=15.905818086582444\n",
      "SGD iter. 445/499: loss=0.028153835675893045, w0=71.40000000000013, w1=17.031750500083614\n",
      "SGD iter. 446/499: loss=52.80462360443844, w0=72.10000000000014, w1=16.45874041706899\n",
      "SGD iter. 447/499: loss=47.06906304966606, w0=71.40000000000013, w1=16.738669409505455\n",
      "SGD iter. 448/499: loss=54.191095831629006, w0=70.70000000000013, w1=16.47795718812359\n",
      "SGD iter. 449/499: loss=1.796996674177374, w0=70.00000000000013, w1=15.598227058291112\n",
      "SGD iter. 450/499: loss=4.648489739386861, w0=70.70000000000013, w1=14.977175484720519\n",
      "SGD iter. 451/499: loss=0.04018477002900905, w0=71.40000000000013, w1=15.581707590574679\n",
      "SGD iter. 452/499: loss=48.032583360610246, w0=70.70000000000013, w1=15.320995369192815\n",
      "SGD iter. 453/499: loss=20.628878630208963, w0=71.40000000000013, w1=15.137529590142396\n",
      "SGD iter. 454/499: loss=0.2703123090985295, w0=70.70000000000013, w1=15.487866523510787\n",
      "SGD iter. 455/499: loss=8.562632729218585, w0=70.00000000000013, w1=15.834950509130778\n",
      "SGD iter. 456/499: loss=113.95755190561012, w0=70.70000000000013, w1=15.310317584419039\n",
      "SGD iter. 457/499: loss=1.3088289780226858, w0=70.00000000000013, w1=16.044431907420027\n",
      "SGD iter. 458/499: loss=159.06398437241273, w0=70.70000000000013, w1=15.017499709827494\n",
      "SGD iter. 459/499: loss=13.900392609874064, w0=71.40000000000013, w1=14.32091495858673\n",
      "SGD iter. 460/499: loss=41.6581588730799, w0=72.10000000000014, w1=14.935575939717117\n",
      "SGD iter. 461/499: loss=0.9075719164982282, w0=71.40000000000013, w1=13.57282454432537\n",
      "SGD iter. 462/499: loss=25.683928470378465, w0=70.70000000000013, w1=14.01301979903234\n",
      "SGD iter. 463/499: loss=74.28728229042721, w0=70.00000000000013, w1=14.693618976688423\n",
      "SGD iter. 464/499: loss=15.90517372672071, w0=69.30000000000013, w1=15.316405383508716\n",
      "SGD iter. 465/499: loss=2.0663930423352794, w0=68.60000000000012, w1=15.868376815446394\n",
      "SGD iter. 466/499: loss=38.23852006779433, w0=69.30000000000013, w1=16.663546540563743\n",
      "SGD iter. 467/499: loss=5.30617208858457, w0=70.00000000000013, w1=15.844888170758114\n",
      "SGD iter. 468/499: loss=3.4190948810037773, w0=70.70000000000013, w1=15.188007203005151\n",
      "SGD iter. 469/499: loss=6.6618714525606055, w0=71.40000000000013, w1=15.913027393085954\n",
      "SGD iter. 470/499: loss=21.0712005104134, w0=72.10000000000014, w1=14.936229914144036\n",
      "SGD iter. 471/499: loss=80.16547822074996, w0=71.40000000000013, w1=14.33082676270005\n",
      "SGD iter. 472/499: loss=0.18077070010424412, w0=72.10000000000014, w1=14.463150289053889\n",
      "SGD iter. 473/499: loss=8.509277032186027, w0=72.80000000000014, w1=14.27968451000347\n",
      "SGD iter. 474/499: loss=15.87577932376476, w0=72.10000000000014, w1=15.098342879809099\n",
      "SGD iter. 475/499: loss=0.433623901641413, w0=72.80000000000014, w1=15.208642913269891\n",
      "SGD iter. 476/499: loss=15.96101022397413, w0=73.50000000000014, w1=15.405162996048393\n",
      "SGD iter. 477/499: loss=24.990258870835618, w0=72.80000000000014, w1=15.485977301537105\n",
      "SGD iter. 478/499: loss=20.64047208791183, w0=72.10000000000014, w1=15.975660834933693\n",
      "SGD iter. 479/499: loss=66.90212169490339, w0=71.40000000000013, w1=15.028748573191264\n",
      "SGD iter. 480/499: loss=27.9251649758159, w0=70.70000000000013, w1=15.537249690931096\n",
      "SGD iter. 481/499: loss=35.56737487687312, w0=71.40000000000013, w1=15.552557357643233\n",
      "SGD iter. 482/499: loss=18.62861002962194, w0=70.70000000000013, w1=15.93784149797136\n",
      "SGD iter. 483/499: loss=5.557417020530769, w0=70.00000000000013, w1=14.88144026659247\n",
      "SGD iter. 484/499: loss=162.2140571480485, w0=70.70000000000013, w1=15.321364709476653\n",
      "SGD iter. 485/499: loss=54.13248119883959, w0=70.00000000000013, w1=15.592844891459231\n",
      "SGD iter. 486/499: loss=8.757313096857455, w0=70.70000000000013, w1=16.206759304836815\n",
      "SGD iter. 487/499: loss=148.43058413285624, w0=71.40000000000013, w1=16.55472635122723\n",
      "SGD iter. 488/499: loss=11.632797938734809, w0=72.10000000000014, w1=16.643253864716357\n",
      "SGD iter. 489/499: loss=18.4244089528384, w0=72.80000000000014, w1=16.83977394749486\n",
      "SGD iter. 490/499: loss=40.5165987080641, w0=73.50000000000014, w1=17.502918264537907\n",
      "SGD iter. 491/499: loss=0.44283339018130163, w0=74.20000000000014, w1=18.135192693019597\n",
      "SGD iter. 492/499: loss=13.13350791846437, w0=73.50000000000014, w1=17.84669542846218\n",
      "SGD iter. 493/499: loss=6.342580282753222, w0=72.80000000000014, w1=18.04744496551143\n",
      "SGD iter. 494/499: loss=10.709349176447231, w0=72.10000000000014, w1=17.28608801489236\n",
      "SGD iter. 495/499: loss=68.31591237113564, w0=71.40000000000013, w1=17.025375793510495\n",
      "SGD iter. 496/499: loss=12.554490080484381, w0=70.70000000000013, w1=17.370552881235493\n",
      "SGD iter. 497/499: loss=3.889271020011696, w0=70.00000000000013, w1=17.451367186724205\n",
      "SGD iter. 498/499: loss=4.321232832104661, w0=70.70000000000013, w1=16.643253445682273\n",
      "SGD iter. 499/499: loss=81.53831427065793, w0=70.00000000000013, w1=16.03785029423829\n",
      "SubSGD: execution time=0.021 seconds\n"
     ]
    }
   ],
   "source": [
    "# Define the parameters of the algorithm.\n",
    "max_iters = 500\n",
    "gamma = 0.7\n",
    "batch_size = 1\n",
    "\n",
    "# Initialization\n",
    "w_initial = np.array([0, 0])\n",
    "\n",
    "# Start SubSGD.\n",
    "start_time = datetime.datetime.now()\n",
    "subsgd_losses, subsgd_ws = stochastic_subgradient_descent(\n",
    "    y, tx, w_initial, batch_size, max_iters, gamma\n",
    ")\n",
    "end_time = datetime.datetime.now()\n",
    "\n",
    "# Print result\n",
    "exection_time = (end_time - start_time).total_seconds()\n",
    "print(\"SubSGD: execution time={t:.3f} seconds\".format(t=exection_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "dc6e87bb0d4947c48243b9a522843764",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(IntSlider(value=1, description='n_iter', max=501, min=1), Output()), _dom_classes=('widg"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.plot_figure(n_iter)>"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from ipywidgets import IntSlider, interact\n",
    "\n",
    "\n",
    "def plot_figure(n_iter):\n",
    "    fig = gradient_descent_visualization(\n",
    "        subsgd_losses,\n",
    "        subsgd_ws,\n",
    "        grid_losses,\n",
    "        grid_w0,\n",
    "        grid_w1,\n",
    "        mean_x,\n",
    "        std_x,\n",
    "        height,\n",
    "        weight,\n",
    "        n_iter,\n",
    "    )\n",
    "    fig.set_size_inches(10.0, 6.0)\n",
    "\n",
    "\n",
    "interact(plot_figure, n_iter=IntSlider(min=1, max=len(subsgd_ws)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
